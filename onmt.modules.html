

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="EN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="EN" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Modules &mdash; OpenNMT-py  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
        <script>mermaid.initialize({startOnLoad:true});</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/theme_overrides.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Translation" href="onmt.translation.html" />
    <link rel="prev" title="Framework" href="onmt.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> OpenNMT-py
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="main.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes.html">Versions</a></li>
<li class="toctree-l1"><a class="reference internal" href="CONTRIBUTING.html">Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="ref.html">References</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Frequently Asked Questions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html">How do I use my v2 models in v3 ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-do-i-train-the-transformer-model">How do I train the Transformer model?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#performance-tips">Performance tips</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#position-encoding-absolute-vs-relative-vs-rotary-embeddings-vs-alibi">Position encoding: Absolute vs Relative vs Rotary Embeddings vs Alibi</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#do-you-support-multi-gpu">Do you support multi-gpu?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-do-i-use-pretrained-embeddings-e-g-glove">How do I use Pretrained embeddings (e.g. GloVe)?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-can-i-ensemble-models-at-inference">How can I ensemble Models at inference?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-can-i-weight-different-corpora-at-training">How can I weight different corpora at training?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#what-special-tokens-does-opennmt-py-use">What special tokens does OpenNMT-py use?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-can-i-apply-on-the-fly-tokenization-and-subword-regularization-when-training">How can I apply on-the-fly tokenization and subword regularization when training?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#what-are-the-readily-available-on-the-fly-data-transforms">What are the readily available on-the-fly data transforms?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-can-i-create-custom-on-the-fly-data-transforms">How can I create custom on-the-fly data transforms?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-to-use-lora-and-8bit-loading-to-finetune-a-big-model">How to use LoRa and 8bit loading to finetune a big model ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-to-use-gradient-checkpointing-when-dealing-with-a-big-model">How to use gradient checkpointing when dealing with a big model ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#can-i-get-word-alignments-while-translating">Can I get word alignments while translating?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-can-i-update-a-checkpoint-s-vocabulary">How can I update a checkpoint’s vocabulary?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-can-i-use-source-word-features">How can I use source word features?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-can-i-set-up-a-translation-server">How can I set up a translation server ?</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="examples/wmt17/Translation.html">Translation WMT17 en-de</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/wiki_103/LanguageModelGeneration.html">Language Model Wiki-103</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/summary/Summarization.html">Summarization CNN/DM</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/ggnn/GGNN.html">Gated Graph Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/replicate_vicuna/ReplicateVicuna.html">Supervised Finetuning of llama 7B to replicate Vicuna</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Scripts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="options/build_vocab.html">Build Vocab</a></li>
<li class="toctree-l1"><a class="reference internal" href="options/train.html">Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="options/translate.html">Translate</a></li>
<li class="toctree-l1"><a class="reference internal" href="options/server.html">Server</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="onmt.html">Framework</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#embeddings">Embeddings</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#onmt.modules.Embeddings"><code class="docutils literal notranslate"><span class="pre">Embeddings</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.modules.Embeddings.emb_luts"><code class="docutils literal notranslate"><span class="pre">Embeddings.emb_luts</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.modules.Embeddings.forward"><code class="docutils literal notranslate"><span class="pre">Embeddings.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.modules.Embeddings.load_pretrained_vectors"><code class="docutils literal notranslate"><span class="pre">Embeddings.load_pretrained_vectors()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.modules.Embeddings.word_lut"><code class="docutils literal notranslate"><span class="pre">Embeddings.word_lut</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.modules.PositionalEncoding"><code class="docutils literal notranslate"><span class="pre">PositionalEncoding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.modules.PositionalEncoding.forward"><code class="docutils literal notranslate"><span class="pre">PositionalEncoding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.modules.position_ffn.PositionwiseFeedForward"><code class="docutils literal notranslate"><span class="pre">PositionwiseFeedForward</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.modules.position_ffn.PositionwiseFeedForward.forward"><code class="docutils literal notranslate"><span class="pre">PositionwiseFeedForward.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#encoders">Encoders</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#onmt.encoders.EncoderBase"><code class="docutils literal notranslate"><span class="pre">EncoderBase</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.encoders.EncoderBase.forward"><code class="docutils literal notranslate"><span class="pre">EncoderBase.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.encoders.TransformerEncoder"><code class="docutils literal notranslate"><span class="pre">TransformerEncoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.encoders.TransformerEncoder.forward"><code class="docutils literal notranslate"><span class="pre">TransformerEncoder.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.encoders.TransformerEncoder.from_opt"><code class="docutils literal notranslate"><span class="pre">TransformerEncoder.from_opt()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.encoders.RNNEncoder"><code class="docutils literal notranslate"><span class="pre">RNNEncoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.encoders.RNNEncoder.forward"><code class="docutils literal notranslate"><span class="pre">RNNEncoder.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.encoders.RNNEncoder.from_opt"><code class="docutils literal notranslate"><span class="pre">RNNEncoder.from_opt()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.encoders.GGNNEncoder"><code class="docutils literal notranslate"><span class="pre">GGNNEncoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.encoders.GGNNEncoder.forward"><code class="docutils literal notranslate"><span class="pre">GGNNEncoder.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.encoders.GGNNEncoder.from_opt"><code class="docutils literal notranslate"><span class="pre">GGNNEncoder.from_opt()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.encoders.CNNEncoder"><code class="docutils literal notranslate"><span class="pre">CNNEncoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.encoders.CNNEncoder.forward"><code class="docutils literal notranslate"><span class="pre">CNNEncoder.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.encoders.CNNEncoder.from_opt"><code class="docutils literal notranslate"><span class="pre">CNNEncoder.from_opt()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.encoders.MeanEncoder"><code class="docutils literal notranslate"><span class="pre">MeanEncoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.encoders.MeanEncoder.forward"><code class="docutils literal notranslate"><span class="pre">MeanEncoder.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.encoders.MeanEncoder.from_opt"><code class="docutils literal notranslate"><span class="pre">MeanEncoder.from_opt()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#decoders">Decoders</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#onmt.decoders.DecoderBase"><code class="docutils literal notranslate"><span class="pre">DecoderBase</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.decoders.DecoderBase.from_opt"><code class="docutils literal notranslate"><span class="pre">DecoderBase.from_opt()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.decoders.TransformerDecoder"><code class="docutils literal notranslate"><span class="pre">TransformerDecoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.decoders.TransformerDecoder.forward"><code class="docutils literal notranslate"><span class="pre">TransformerDecoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.decoders.decoder.RNNDecoderBase"><code class="docutils literal notranslate"><span class="pre">RNNDecoderBase</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.decoders.decoder.RNNDecoderBase.forward"><code class="docutils literal notranslate"><span class="pre">RNNDecoderBase.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.decoders.decoder.RNNDecoderBase.from_opt"><code class="docutils literal notranslate"><span class="pre">RNNDecoderBase.from_opt()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.decoders.decoder.RNNDecoderBase.init_state"><code class="docutils literal notranslate"><span class="pre">RNNDecoderBase.init_state()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.decoders.StdRNNDecoder"><code class="docutils literal notranslate"><span class="pre">StdRNNDecoder</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.decoders.InputFeedRNNDecoder"><code class="docutils literal notranslate"><span class="pre">InputFeedRNNDecoder</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.decoders.CNNDecoder"><code class="docutils literal notranslate"><span class="pre">CNNDecoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.decoders.CNNDecoder.forward"><code class="docutils literal notranslate"><span class="pre">CNNDecoder.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.decoders.CNNDecoder.from_opt"><code class="docutils literal notranslate"><span class="pre">CNNDecoder.from_opt()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.decoders.CNNDecoder.init_state"><code class="docutils literal notranslate"><span class="pre">CNNDecoder.init_state()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#attention">Attention</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#onmt.modules.GlobalAttention"><code class="docutils literal notranslate"><span class="pre">GlobalAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.modules.GlobalAttention.forward"><code class="docutils literal notranslate"><span class="pre">GlobalAttention.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.modules.GlobalAttention.score"><code class="docutils literal notranslate"><span class="pre">GlobalAttention.score()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.modules.MultiHeadedAttention"><code class="docutils literal notranslate"><span class="pre">MultiHeadedAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.modules.MultiHeadedAttention.forward"><code class="docutils literal notranslate"><span class="pre">MultiHeadedAttention.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.modules.AverageAttention"><code class="docutils literal notranslate"><span class="pre">AverageAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.modules.AverageAttention.forward"><code class="docutils literal notranslate"><span class="pre">AverageAttention.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.modules.ConvMultiStepAttention"><code class="docutils literal notranslate"><span class="pre">ConvMultiStepAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.modules.ConvMultiStepAttention.apply_mask"><code class="docutils literal notranslate"><span class="pre">ConvMultiStepAttention.apply_mask()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.modules.ConvMultiStepAttention.forward"><code class="docutils literal notranslate"><span class="pre">ConvMultiStepAttention.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.modules.CopyGenerator"><code class="docutils literal notranslate"><span class="pre">CopyGenerator</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.modules.CopyGenerator.forward"><code class="docutils literal notranslate"><span class="pre">CopyGenerator.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.modules.structured_attention.MatrixTree"><code class="docutils literal notranslate"><span class="pre">MatrixTree</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.modules.structured_attention.MatrixTree.forward"><code class="docutils literal notranslate"><span class="pre">MatrixTree.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="onmt.translation.html">Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="onmt.translate.translation_server.html">Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="onmt.inputters.html">Data Loaders</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Legacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="legacy/FAQ.html">FAQ (Legacy version)</a></li>
<li class="toctree-l1"><a class="reference internal" href="legacy/im2text.html">Image to Text</a></li>
<li class="toctree-l1"><a class="reference internal" href="legacy/speech2text.html">Speech to Text</a></li>
<li class="toctree-l1"><a class="reference internal" href="legacy/vid2text.html">Video to Text</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">OpenNMT-py</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Modules</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/onmt.modules.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="modules">
<h1>Modules<a class="headerlink" href="#modules" title="Permalink to this heading">¶</a></h1>
<section id="embeddings">
<h2>Embeddings<a class="headerlink" href="#embeddings" title="Permalink to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="onmt.modules.Embeddings">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.modules.</span></span><span class="sig-name descname"><span class="pre">Embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">word_vec_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">word_vocab_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">word_padding_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">position_encoding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">position_encoding_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'SinusoidalInterleaved'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feat_merge</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'concat'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feat_vec_exponent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feat_vec_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feat_padding_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feat_vocab_sizes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">freeze_word_vecs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/embeddings.html#Embeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.Embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Words embeddings for encoder/decoder.</p>
<p>Additionally includes ability to add sparse input features
based on “Linguistic Input Features Improve Neural Machine Translation”
<span id="id1">[<a class="reference internal" href="ref.html#id3" title="Rico Sennrich and Barry Haddow. Linguistic input features improve neural machine translation. arXiv preprint arXiv:1606.02892, 2016.">SH16</a>]</span>.</p>
<div class="mermaid">
            graph LR
   A[Input]
   C[Feature 1 Lookup]
   A--&gt;B[Word Lookup]
   A--&gt;C
   A--&gt;D[Feature N Lookup]
   B--&gt;E[MLP/Concat]
   C--&gt;E
   D--&gt;E
   E--&gt;F[Output]
        </div><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>word_vec_size</strong> (<em>int</em>) – size of the dictionary of embeddings.</p></li>
<li><p><strong>word_vocab_size</strong> (<em>int</em>) – size of dictionary of embeddings for words.</p></li>
<li><p><strong>word_padding_idx</strong> (<em>int</em>) – padding index for words in the embeddings.</p></li>
<li><p><strong>position_encoding</strong> (<em>bool</em>) – see <a class="reference internal" href="#onmt.modules.PositionalEncoding" title="onmt.modules.PositionalEncoding"><code class="xref py py-class docutils literal notranslate"><span class="pre">PositionalEncoding</span></code></a></p></li>
<li><p><strong>feat_merge</strong> (<em>string</em>) – merge action for the features embeddings:
concat, sum or mlp.</p></li>
<li><p><strong>feat_vec_exponent</strong> (<em>float</em>) – when using <cite>-feat_merge concat</cite>, feature
embedding size is N^feat_dim_exponent, where N is the
number of values the feature takes.</p></li>
<li><p><strong>feat_vec_size</strong> (<em>int</em>) – embedding dimension for features when using
<cite>-feat_merge mlp</cite></p></li>
<li><p><strong>feat_padding_idx</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – padding index for a list of features
in the embeddings.</p></li>
<li><p><strong>feat_vocab_sizes</strong> (<em>List</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>) – list of size of dictionary
of embeddings for each feature.</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – dropout probability.</p></li>
<li><p><strong>sparse</strong> (<em>bool</em>) – sparse embbedings default False</p></li>
<li><p><strong>freeze_word_vecs</strong> (<em>bool</em>) – freeze weights of word vectors.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="onmt.modules.Embeddings.emb_luts">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">emb_luts</span></span><a class="headerlink" href="#onmt.modules.Embeddings.emb_luts" title="Permalink to this definition">¶</a></dt>
<dd><p>Embedding look-up table.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.modules.Embeddings.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/embeddings.html#Embeddings.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.Embeddings.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the embeddings for words and features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>source</strong> (<em>LongTensor</em>) – index tensor <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">len,</span> <span class="pre">nfeat)</span></code></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Word embeddings <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">len,</span> <span class="pre">embedding_size)</span></code></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>FloatTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.modules.Embeddings.load_pretrained_vectors">
<span class="sig-name descname"><span class="pre">load_pretrained_vectors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">emb_file</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/embeddings.html#Embeddings.load_pretrained_vectors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.Embeddings.load_pretrained_vectors" title="Permalink to this definition">¶</a></dt>
<dd><p>Load in pretrained embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>emb_file</strong> (<em>str</em>) – path to torch serialized embeddings</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="onmt.modules.Embeddings.word_lut">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">word_lut</span></span><a class="headerlink" href="#onmt.modules.Embeddings.word_lut" title="Permalink to this definition">¶</a></dt>
<dd><p>Word look-up table.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.modules.PositionalEncoding">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.modules.</span></span><span class="sig-name descname"><span class="pre">PositionalEncoding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enc_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/embeddings.html#PositionalEncoding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.PositionalEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Sinusoidal positional encoding for non-recurrent neural networks.</p>
<p>Implementation based on “Attention Is All You Need”
<span id="id2">[<a class="reference internal" href="ref.html#id32" title="Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. CoRR, 2017. URL: http://arxiv.org/abs/1706.03762, arXiv:1706.03762.">VSP+17</a>]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dim</strong> (<em>int</em>) – embedding size</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.modules.PositionalEncoding.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">emb</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/embeddings.html#PositionalEncoding.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.PositionalEncoding.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Embed inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>emb</strong> (<em>FloatTensor</em>) – Sequence of word vectors
<code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">seq_len,</span> <span class="pre">self.dim)</span></code></p></li>
<li><p><strong>step</strong> (<em>int</em><em> or </em><em>NoneType</em>) – If stepwise (<code class="docutils literal notranslate"><span class="pre">seq_len</span> <span class="pre">=</span> <span class="pre">1</span></code>), use
the encoding for this position.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.modules.position_ffn.PositionwiseFeedForward">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.modules.position_ffn.</span></span><span class="sig-name descname"><span class="pre">PositionwiseFeedForward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_ff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'relu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_ffnbias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel_residual</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'standard'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_ckpting</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel_gpu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/position_ffn.html#PositionwiseFeedForward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.position_ffn.PositionwiseFeedForward" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>A two-layer Feed-Forward-Network with residual layer norm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> (<em>int</em>) – the size of input for the first-layer of the FFN.</p></li>
<li><p><strong>d_ff</strong> (<em>int</em>) – the hidden layer size of the second-layer
of the FNN.</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – dropout probability in <span class="math notranslate nohighlight">\([0, 1)\)</span>.</p></li>
<li><p><strong>activation_fn</strong> (<em>ActivationFunction</em>) – activation function used.</p></li>
<li><p><strong>layer_norm</strong> (<em>string</em>) – ‘standard’ or ‘rms’</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.modules.position_ffn.PositionwiseFeedForward.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/position_ffn.html#PositionwiseFeedForward.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.position_ffn.PositionwiseFeedForward.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Layer definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">input_len,</span> <span class="pre">model_dim)</span></code></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">input_len,</span> <span class="pre">model_dim)</span></code>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(FloatTensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="encoders">
<h2>Encoders<a class="headerlink" href="#encoders" title="Permalink to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="onmt.encoders.EncoderBase">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.encoders.</span></span><span class="sig-name descname"><span class="pre">EncoderBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/encoder.html#EncoderBase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.EncoderBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Base encoder class. Specifies the interface used by different encoder types
and required by <code class="xref py py-class docutils literal notranslate"><span class="pre">onmt.Models.NMTModel</span></code>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.encoders.EncoderBase.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/encoder.html#EncoderBase.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.EncoderBase.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> (<em>LongTensor</em>) – padded sequences of sparse indices <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">src_len,</span> <span class="pre">nfeat)</span></code></p></li>
<li><p><strong>src_len</strong> (<em>LongTensor</em>) – length of each sequence <code class="docutils literal notranslate"><span class="pre">(batch,)</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>enc_out (encoder output used for attention),
<code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">src_len,</span> <span class="pre">hidden_size)</span></code>
for bidirectional rnn last dimension is 2x hidden_size</p></li>
<li><p>enc_final_hs: encoder final hidden state
<code class="docutils literal notranslate"><span class="pre">(num_layers</span> <span class="pre">x</span> <span class="pre">dir,</span> <span class="pre">batch,</span> <span class="pre">hidden_size)</span></code>
In the case of LSTM this is a tuple.</p></li>
<li><p>src_len <code class="docutils literal notranslate"><span class="pre">(batch)</span></code></p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(FloatTensor, FloatTensor, FloatTensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.encoders.TransformerEncoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.encoders.</span></span><span class="sig-name descname"><span class="pre">TransformerEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_ff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_relative_positions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relative_positions_buckets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_ffn_activation_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'relu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_qkvbias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_kv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_ffnbias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel_residual</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'standard'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_ckpting</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel_gpu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rotary_interleave</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rotary_theta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rotary_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/transformer.html#TransformerEncoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.TransformerEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#onmt.encoders.EncoderBase" title="onmt.encoders.encoder.EncoderBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderBase</span></code></a></p>
<p>The Transformer encoder from “Attention is All You Need”
<span id="id3">[<a class="reference internal" href="ref.html#id32" title="Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. CoRR, 2017. URL: http://arxiv.org/abs/1706.03762, arXiv:1706.03762.">VSP+17</a>]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_layers</strong> (<em>int</em>) – number of encoder layers</p></li>
<li><p><strong>d_model</strong> (<em>int</em>) – size of the model</p></li>
<li><p><strong>heads</strong> (<em>int</em>) – number of heads</p></li>
<li><p><strong>d_ff</strong> (<em>int</em>) – size of the inner FF layer</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – dropout parameters</p></li>
<li><p><strong>embeddings</strong> (<a class="reference internal" href="#onmt.modules.Embeddings" title="onmt.modules.Embeddings"><em>onmt.modules.Embeddings</em></a>) – embeddings to use, should have positional encodings</p></li>
<li><p><strong>pos_ffn_activation_fn</strong> (<em>ActivationFunction</em>) – activation function choice for PositionwiseFeedForward layer</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>enc_out <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">src_len,</span> <span class="pre">model_dim)</span></code></p></li>
<li><p>encoder final state: None in the case of Transformer</p></li>
<li><p>src_len <code class="docutils literal notranslate"><span class="pre">(batch_size)</span></code></p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(torch.FloatTensor, torch.FloatTensor)</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.encoders.TransformerEncoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/transformer.html#TransformerEncoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.TransformerEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>See <a class="reference internal" href="#onmt.encoders.EncoderBase.forward" title="onmt.encoders.EncoderBase.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">EncoderBase.forward()</span></code></a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.encoders.TransformerEncoder.from_opt">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_opt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/transformer.html#TransformerEncoder.from_opt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.TransformerEncoder.from_opt" title="Permalink to this definition">¶</a></dt>
<dd><p>Alternate constructor.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.encoders.RNNEncoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.encoders.</span></span><span class="sig-name descname"><span class="pre">RNNEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rnn_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bridge</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/rnn_encoder.html#RNNEncoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.RNNEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#onmt.encoders.EncoderBase" title="onmt.encoders.encoder.EncoderBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderBase</span></code></a></p>
<p>A generic recurrent neural network encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rnn_type</strong> (<em>str</em>) – style of recurrent unit to use, one of [RNN, LSTM, GRU, SRU]</p></li>
<li><p><strong>bidirectional</strong> (<em>bool</em>) – use a bidirectional RNN</p></li>
<li><p><strong>num_layers</strong> (<em>int</em>) – number of stacked layers</p></li>
<li><p><strong>hidden_size</strong> (<em>int</em>) – hidden size of each layer</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – dropout value for <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Dropout</span></code></p></li>
<li><p><strong>embeddings</strong> (<a class="reference internal" href="#onmt.modules.Embeddings" title="onmt.modules.Embeddings"><em>onmt.modules.Embeddings</em></a>) – embedding module to use</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.encoders.RNNEncoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/rnn_encoder.html#RNNEncoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.RNNEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>See <a class="reference internal" href="#onmt.encoders.EncoderBase.forward" title="onmt.encoders.EncoderBase.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">EncoderBase.forward()</span></code></a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.encoders.RNNEncoder.from_opt">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_opt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/rnn_encoder.html#RNNEncoder.from_opt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.RNNEncoder.from_opt" title="Permalink to this definition">¶</a></dt>
<dd><p>Alternate constructor.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.encoders.GGNNEncoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.encoders.</span></span><span class="sig-name descname"><span class="pre">GGNNEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rnn_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_word_vec_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_ggnn_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidir_edges</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_edge_types</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bridge_extra_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_vocab</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/ggnn_encoder.html#GGNNEncoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.GGNNEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#onmt.encoders.EncoderBase" title="onmt.encoders.encoder.EncoderBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderBase</span></code></a></p>
<dl class="simple">
<dt>A gated graph neural network configured as an encoder.</dt><dd><p>Based on github.com/JamesChuanggg/ggnn.pytorch.git,
which is based on the paper “Gated Graph Sequence Neural Networks”
by Y. Li, D. Tarlow, M. Brockschmidt, and R. Zemel.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rnn_type</strong> (<em>str</em>) – style of recurrent unit to use, one of [LSTM]</p></li>
<li><p><strong>src_ggnn_size</strong> (<em>int</em>) – Size of token-to-node embedding input</p></li>
<li><p><strong>src_word_vec_size</strong> (<em>int</em>) – Size of token-to-node embedding output</p></li>
<li><p><strong>state_dim</strong> (<em>int</em>) – Number of state dimensions in nodes</p></li>
<li><p><strong>n_edge_types</strong> (<em>int</em>) – Number of edge types</p></li>
<li><p><strong>bidir_edges</strong> (<em>bool</em>) – True if reverse edges should be autocreated</p></li>
<li><p><strong>n_node</strong> (<em>int</em>) – Max nodes in graph</p></li>
<li><p><strong>bridge_extra_node</strong> (<em>bool</em>) – True indicates only 1st extra node
(after token listing) should be used for decoder init.</p></li>
<li><p><strong>n_steps</strong> (<em>int</em>) – Steps to advance graph encoder for stabilization</p></li>
<li><p><strong>src_vocab</strong> (<em>int</em>) – Path to source vocabulary.(The ggnn uses src_vocab
during training because the graph is built using edge information
which requires parsing the input sequence.)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.encoders.GGNNEncoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/ggnn_encoder.html#GGNNEncoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.GGNNEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>See <a class="reference internal" href="#onmt.encoders.EncoderBase.forward" title="onmt.encoders.EncoderBase.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">EncoderBase.forward()</span></code></a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.encoders.GGNNEncoder.from_opt">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_opt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/ggnn_encoder.html#GGNNEncoder.from_opt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.GGNNEncoder.from_opt" title="Permalink to this definition">¶</a></dt>
<dd><p>Alternate constructor.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.encoders.CNNEncoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.encoders.</span></span><span class="sig-name descname"><span class="pre">CNNEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cnn_kernel_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/cnn_encoder.html#CNNEncoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.CNNEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#onmt.encoders.EncoderBase" title="onmt.encoders.encoder.EncoderBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderBase</span></code></a></p>
<p>Encoder based on “Convolutional Sequence to Sequence Learning”
<span id="id4">[<a class="reference internal" href="ref.html#id33" title="Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolutional sequence to sequence learning. CoRR, 2017. URL: http://arxiv.org/abs/1705.03122, arXiv:1705.03122.">GAG+17</a>]</span>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.encoders.CNNEncoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/cnn_encoder.html#CNNEncoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.CNNEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>See <a class="reference internal" href="#onmt.encoders.EncoderBase.forward" title="onmt.encoders.EncoderBase.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">EncoderBase.forward()</span></code></a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.encoders.CNNEncoder.from_opt">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_opt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/cnn_encoder.html#CNNEncoder.from_opt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.CNNEncoder.from_opt" title="Permalink to this definition">¶</a></dt>
<dd><p>Alternate constructor.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.encoders.MeanEncoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.encoders.</span></span><span class="sig-name descname"><span class="pre">MeanEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/mean_encoder.html#MeanEncoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.MeanEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#onmt.encoders.EncoderBase" title="onmt.encoders.encoder.EncoderBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">EncoderBase</span></code></a></p>
<p>A trivial non-recurrent encoder. Simply applies mean pooling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_layers</strong> (<em>int</em>) – number of replicated layers</p></li>
<li><p><strong>embeddings</strong> (<a class="reference internal" href="#onmt.modules.Embeddings" title="onmt.modules.Embeddings"><em>onmt.modules.Embeddings</em></a>) – embedding module to use</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.encoders.MeanEncoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/mean_encoder.html#MeanEncoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.MeanEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>See <a class="reference internal" href="#onmt.encoders.EncoderBase.forward" title="onmt.encoders.EncoderBase.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">EncoderBase.forward()</span></code></a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.encoders.MeanEncoder.from_opt">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_opt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/encoders/mean_encoder.html#MeanEncoder.from_opt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.encoders.MeanEncoder.from_opt" title="Permalink to this definition">¶</a></dt>
<dd><p>Alternate constructor.</p>
</dd></dl>

</dd></dl>

</section>
<section id="decoders">
<h2>Decoders<a class="headerlink" href="#decoders" title="Permalink to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="onmt.decoders.DecoderBase">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.decoders.</span></span><span class="sig-name descname"><span class="pre">DecoderBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attentional</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/decoders/decoder.html#DecoderBase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.decoders.DecoderBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract class for decoders.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>attentional</strong> (<em>bool</em>) – The decoder returns non-empty attention.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.decoders.DecoderBase.from_opt">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_opt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/decoders/decoder.html#DecoderBase.from_opt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.decoders.DecoderBase.from_opt" title="Permalink to this definition">¶</a></dt>
<dd><p>Alternate constructor.</p>
<p>Subclasses should override this method.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.decoders.TransformerDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.decoders.</span></span><span class="sig-name descname"><span class="pre">TransformerDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_ff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy_attn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">self_attn_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_relative_positions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relative_positions_buckets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aan_useffn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_context_alignment</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alignment_layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alignment_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_ffn_activation_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'relu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_qkvbias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_kv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_ffnbias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel_residual</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shared_layer_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'standard'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_ckpting</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel_gpu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sliding_window</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rotary_interleave</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rotary_theta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rotary_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_experts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_experts_per_tok</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/decoders/transformer.html#TransformerDecoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.decoders.TransformerDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">TransformerDecoderBase</span></code></p>
<p>The Transformer decoder from “Attention is All You Need”.
<span id="id5">[<a class="reference internal" href="ref.html#id32" title="Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. CoRR, 2017. URL: http://arxiv.org/abs/1706.03762, arXiv:1706.03762.">VSP+17</a>]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_layers</strong> (<em>int</em>) – number of decoder layers.</p></li>
<li><p><strong>d_model</strong> (<em>int</em>) – size of the model</p></li>
<li><p><strong>heads</strong> (<em>int</em>) – number of heads</p></li>
<li><p><strong>d_ff</strong> (<em>int</em>) – size of the inner FF layer</p></li>
<li><p><strong>copy_attn</strong> (<em>bool</em>) – if using a separate copy attention</p></li>
<li><p><strong>self_attn_type</strong> (<em>str</em>) – type of self-attention scaled-dot, scaled-dot-flash, average</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – dropout in residual, self-attn(dot) and feed-forward</p></li>
<li><p><strong>attention_dropout</strong> (<em>float</em>) – dropout in context_attn (and self-attn(avg))</p></li>
<li><p><strong>embeddings</strong> (<a class="reference internal" href="#onmt.modules.Embeddings" title="onmt.modules.Embeddings"><em>onmt.modules.Embeddings</em></a>) – embeddings to use, should have positional encodings</p></li>
<li><p><strong>max_relative_positions</strong> (<em>int</em>) – Max distance between inputs in relative positions representations</p></li>
<li><p><strong>relative_positions_buckets</strong> (<em>int</em>) – Number of buckets when using relative position bias</p></li>
<li><p><strong>aan_useffn</strong> (<em>bool</em>) – Turn on the FFN layer in the AAN decoder</p></li>
<li><p><strong>full_context_alignment</strong> (<em>bool</em>) – whether enable an extra full context decoder forward for alignment</p></li>
<li><p><strong>alignment_layer</strong> (<em>int</em>) – N° Layer to supervise with for alignment guiding</p></li>
<li><p><strong>alignment_heads</strong> (<em>int</em>) – <ol class="upperalpha simple" start="14">
<li><p>of cross attention heads to use for alignment guiding</p></li>
</ol>
</p></li>
<li><p><strong>pos_ffn_activation_fn</strong> (<em>ActivationFunction</em>) – activation function choice for PositionwiseFeedForward layer</p></li>
<li><p><strong>add_qkvbias</strong> (<em>bool</em>) – whether to add bias to the Key/Value nn.Linear</p></li>
<li><p><strong>num_kv</strong> (<em>int</em>) – number of heads for KV when different vs Q (multiquery)</p></li>
<li><p><strong>add_ffnbias</strong> (<em>bool</em>) – whether to add bias to the FF nn.Linear</p></li>
<li><p><strong>parallel_residual</strong> (<em>bool</em>) – Use parallel residual connections in each layer block, as used
by the GPT-J and GPT-NeoX models</p></li>
<li><p><strong>shared_layer_norm</strong> (<em>bool</em>) – When using parallel residual, share the input and post
attention layer norms.</p></li>
<li><p><strong>layer_norm</strong> (<em>string</em>) – type of layer normalization standard/rms</p></li>
<li><p><strong>norm_eps</strong> (<em>float</em>) – layer norm epsilon</p></li>
<li><p><strong>use_ckpting</strong> (<em>List</em>) – layers for which we checkpoint for backward</p></li>
<li><p><strong>parallel_gpu</strong> (<em>int</em>) – Number of gpu for tensor parallelism</p></li>
<li><p><strong>sliding_window</strong> (<em>int</em>) – Width of the band mask and KV cache (cf Mistral Model)</p></li>
<li><p><strong>rotary_interleave</strong> (<em>bool</em>) – Interleave the head dimensions when rotary embeddings are applied</p></li>
<li><p><strong>rotary_theta</strong> (<em>int</em>) – rotary base theta</p></li>
<li><p><strong>rotary_dim</strong> (<em>int</em>) – in some cases the rotary dim is lower than head dim</p></li>
<li><p><strong>num_experts</strong> (<em>int</em>) – Number of experts for MoE</p></li>
<li><p><strong>num_experts_per_tok</strong> (<em>int</em>) – Number of experts choice per token</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.decoders.TransformerDecoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tgt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enc_out</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/decoders/transformer.html#TransformerDecoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.decoders.TransformerDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Decode, possibly stepwise.
when training step is always None, when decoding, step increases
tgt (Tensor): batch x tlen x feats
enc_out (Tensor): encoder output (batch x slen x model_dim)</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.decoders.decoder.RNNDecoderBase">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.decoders.decoder.</span></span><span class="sig-name descname"><span class="pre">RNNDecoderBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rnn_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional_encoder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'general'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'softmax'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coverage_attn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_gate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy_attn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reuse_copy_attn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy_attn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'general'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/decoders/decoder.html#RNNDecoderBase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.decoders.decoder.RNNDecoderBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#onmt.decoders.DecoderBase" title="onmt.decoders.decoder.DecoderBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">DecoderBase</span></code></a></p>
<p>Base recurrent attention-based decoder class.</p>
<p>Specifies the interface used by different decoder types
and required by <a class="reference internal" href="onmt.html#onmt.models.NMTModel" title="onmt.models.NMTModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">NMTModel</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rnn_type</strong> (<em>str</em>) – style of recurrent unit to use, one of [RNN, LSTM, GRU, SRU]</p></li>
<li><p><strong>bidirectional_encoder</strong> (<em>bool</em>) – use with a bidirectional encoder</p></li>
<li><p><strong>num_layers</strong> (<em>int</em>) – number of stacked layers</p></li>
<li><p><strong>hidden_size</strong> (<em>int</em>) – hidden size of each layer</p></li>
<li><p><strong>attn_type</strong> (<em>str</em>) – see <a class="reference internal" href="#onmt.modules.GlobalAttention" title="onmt.modules.GlobalAttention"><code class="xref py py-class docutils literal notranslate"><span class="pre">GlobalAttention</span></code></a></p></li>
<li><p><strong>attn_func</strong> (<em>str</em>) – see <a class="reference internal" href="#onmt.modules.GlobalAttention" title="onmt.modules.GlobalAttention"><code class="xref py py-class docutils literal notranslate"><span class="pre">GlobalAttention</span></code></a></p></li>
<li><p><strong>coverage_attn</strong> (<em>str</em>) – see <a class="reference internal" href="#onmt.modules.GlobalAttention" title="onmt.modules.GlobalAttention"><code class="xref py py-class docutils literal notranslate"><span class="pre">GlobalAttention</span></code></a></p></li>
<li><p><strong>context_gate</strong> (<em>str</em>) – see <code class="xref py py-class docutils literal notranslate"><span class="pre">ContextGate</span></code></p></li>
<li><p><strong>copy_attn</strong> (<em>bool</em>) – setup a separate copy attention mechanism</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – dropout value for <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Dropout</span></code></p></li>
<li><p><strong>embeddings</strong> (<a class="reference internal" href="#onmt.modules.Embeddings" title="onmt.modules.Embeddings"><em>onmt.modules.Embeddings</em></a>) – embedding module to use</p></li>
<li><p><strong>reuse_copy_attn</strong> (<em>bool</em>) – reuse the attention for copying</p></li>
<li><p><strong>copy_attn_type</strong> (<em>str</em>) – The copy attention style. See
<a class="reference internal" href="#onmt.modules.GlobalAttention" title="onmt.modules.GlobalAttention"><code class="xref py py-class docutils literal notranslate"><span class="pre">GlobalAttention</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.decoders.decoder.RNNDecoderBase.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tgt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enc_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/decoders/decoder.html#RNNDecoderBase.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.decoders.decoder.RNNDecoderBase.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tgt</strong> (<em>LongTensor</em>) – sequences of padded tokens
<code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">tgt_len,</span> <span class="pre">nfeats)</span></code>.</p></li>
<li><p><strong>enc_out</strong> (<em>FloatTensor</em>) – vectors from the encoder
<code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">src_len,</span> <span class="pre">hidden)</span></code>.</p></li>
<li><p><strong>src_len</strong> (<em>LongTensor</em>) – the padded source lengths
<code class="docutils literal notranslate"><span class="pre">(batch,)</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>dec_outs: output from the decoder (after attn)
<code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">tgt_len,</span> <span class="pre">hidden)</span></code>.</p></li>
<li><p>attns: distribution over src at each tgt
<code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">tgt_len,</span> <span class="pre">src_len)</span></code>.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(FloatTensor, dict[str, FloatTensor])</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.decoders.decoder.RNNDecoderBase.from_opt">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_opt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/decoders/decoder.html#RNNDecoderBase.from_opt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.decoders.decoder.RNNDecoderBase.from_opt" title="Permalink to this definition">¶</a></dt>
<dd><p>Alternate constructor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.decoders.decoder.RNNDecoderBase.init_state">
<span class="sig-name descname"><span class="pre">init_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enc_final_hs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/decoders/decoder.html#RNNDecoderBase.init_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.decoders.decoder.RNNDecoderBase.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize decoder state with last state of the encoder.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.decoders.StdRNNDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.decoders.</span></span><span class="sig-name descname"><span class="pre">StdRNNDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rnn_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional_encoder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'general'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'softmax'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coverage_attn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_gate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy_attn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reuse_copy_attn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy_attn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'general'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/decoders/decoder.html#StdRNNDecoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.decoders.StdRNNDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#onmt.decoders.decoder.RNNDecoderBase" title="onmt.decoders.decoder.RNNDecoderBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">RNNDecoderBase</span></code></a></p>
<p>Standard fully batched RNN decoder with attention.</p>
<p>Faster implementation, uses CuDNN for implementation.
See <a class="reference internal" href="#onmt.decoders.decoder.RNNDecoderBase" title="onmt.decoders.decoder.RNNDecoderBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">RNNDecoderBase</span></code></a> for options.</p>
<p>Based around the approach from
“Neural Machine Translation By Jointly Learning To Align and Translate”
<span id="id6">[<a class="reference internal" href="ref.html#id5" title="Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural Machine Translation By Jointly Learning To Align and Translate. In ICLR, 1–15. 2014. URL: http://arxiv.org/abs/1409.0473 http://arxiv.org/abs/1409.0473v3, arXiv:1409.0473, doi:10.1146/annurev.neuro.26.041002.131047.">BCB14</a>]</span></p>
<p>Implemented without input_feeding and currently with no <cite>coverage_attn</cite>
or <cite>copy_attn</cite> support.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.decoders.InputFeedRNNDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.decoders.</span></span><span class="sig-name descname"><span class="pre">InputFeedRNNDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rnn_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional_encoder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'general'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'softmax'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coverage_attn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_gate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy_attn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reuse_copy_attn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy_attn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'general'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/decoders/decoder.html#InputFeedRNNDecoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.decoders.InputFeedRNNDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#onmt.decoders.decoder.RNNDecoderBase" title="onmt.decoders.decoder.RNNDecoderBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">RNNDecoderBase</span></code></a></p>
<p>Input feeding based decoder.</p>
<p>See <a class="reference internal" href="#onmt.decoders.decoder.RNNDecoderBase" title="onmt.decoders.decoder.RNNDecoderBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">RNNDecoderBase</span></code></a> for options.</p>
<p>Based around the input feeding approach from
“Effective Approaches to Attention-based Neural Machine Translation”
<span id="id7">[<a class="reference internal" href="ref.html#id10" title="Minh-Thang Luong, Hieu Pham, and Christopher D. Manning. Effective Approaches to Attention-based Neural Machine Translation. In Proc of EMNLP. 2015.">LPM15</a>]</span></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.decoders.CNNDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.decoders.</span></span><span class="sig-name descname"><span class="pre">CNNDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy_attn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cnn_kernel_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy_attn_type</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/decoders/cnn_decoder.html#CNNDecoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.decoders.CNNDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#onmt.decoders.DecoderBase" title="onmt.decoders.decoder.DecoderBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">DecoderBase</span></code></a></p>
<p>Decoder based on “Convolutional Sequence to Sequence Learning”
<span id="id8">[<a class="reference internal" href="ref.html#id33" title="Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolutional sequence to sequence learning. CoRR, 2017. URL: http://arxiv.org/abs/1705.03122, arXiv:1705.03122.">GAG+17</a>]</span>.</p>
<p>Consists of residual convolutional layers, with ConvMultiStepAttention.</p>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.decoders.CNNDecoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tgt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enc_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/decoders/cnn_decoder.html#CNNDecoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.decoders.CNNDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="xref py py-obj docutils literal notranslate"><span class="pre">onmt.modules.RNNDecoderBase.forward()</span></code></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.decoders.CNNDecoder.from_opt">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_opt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/decoders/cnn_decoder.html#CNNDecoder.from_opt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.decoders.CNNDecoder.from_opt" title="Permalink to this definition">¶</a></dt>
<dd><p>Alternate constructor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.decoders.CNNDecoder.init_state">
<span class="sig-name descname"><span class="pre">init_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enc_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enc_hidden</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/decoders/cnn_decoder.html#CNNDecoder.init_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.decoders.CNNDecoder.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Init decoder state.</p>
</dd></dl>

</dd></dl>

</section>
<section id="attention">
<h2>Attention<a class="headerlink" href="#attention" title="Permalink to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="onmt.modules.GlobalAttention">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.modules.</span></span><span class="sig-name descname"><span class="pre">GlobalAttention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coverage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'dot'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'softmax'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/global_attention.html#GlobalAttention"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.GlobalAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Global attention takes a matrix and a query vector. It
then computes a parameterized convex combination of the matrix
based on the input query.</p>
<p>Constructs a unit mapping a query <cite>q</cite> of size <cite>dim</cite>
and a source matrix <cite>H</cite> of size <cite>n x dim</cite>, to an output
of size <cite>dim</cite>.</p>
<div class="mermaid">
            graph BT
   A[Query]
   subgraph RNN
     C[H 1]
     D[H 2]
     E[H N]
   end
   F[Attn]
   G[Output]
   A --&gt; F
   C --&gt; F
   D --&gt; F
   E --&gt; F
   C -.-&gt; G
   D -.-&gt; G
   E -.-&gt; G
   F --&gt; G
        </div><p>All models compute the output as
<span class="math notranslate nohighlight">\(c = \sum_{j=1}^{\text{SeqLength}} a_j H_j\)</span> where
<span class="math notranslate nohighlight">\(a_j\)</span> is the softmax of a score function.
Then then apply a projection layer to [q, c].</p>
<p>However they
differ on how they compute the attention score.</p>
<ul class="simple">
<li><dl class="simple">
<dt>Luong Attention (dot, general):</dt><dd><ul>
<li><p>dot: <span class="math notranslate nohighlight">\(\text{score}(H_j,q) = H_j^T q\)</span></p></li>
<li><p>general: <span class="math notranslate nohighlight">\(\text{score}(H_j, q) = H_j^T W_a q\)</span></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Bahdanau Attention (mlp):</dt><dd><ul>
<li><p><span class="math notranslate nohighlight">\(\text{score}(H_j, q) = v_a^T \text{tanh}(W_a q + U_a h_j)\)</span></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim</strong> (<em>int</em>) – dimensionality of query and key</p></li>
<li><p><strong>coverage</strong> (<em>bool</em>) – use coverage term</p></li>
<li><p><strong>attn_type</strong> (<em>str</em>) – type of attention to use, options [dot,general,mlp]</p></li>
<li><p><strong>attn_func</strong> (<em>str</em>) – attention function to use, options [softmax,sparsemax]</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.modules.GlobalAttention.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enc_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_len</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coverage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/global_attention.html#GlobalAttention.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.GlobalAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> (<em>FloatTensor</em>) – query vectors <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">tgt_len,</span> <span class="pre">dim)</span></code></p></li>
<li><p><strong>enc_out</strong> (<em>FloatTensor</em>) – encoder out vectors <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">src_len,</span> <span class="pre">dim)</span></code></p></li>
<li><p><strong>src_len</strong> (<em>LongTensor</em>) – source context lengths <code class="docutils literal notranslate"><span class="pre">(batch,)</span></code></p></li>
<li><p><strong>coverage</strong> (<em>FloatTensor</em>) – None (not supported yet)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>Computed vector <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">tgt_len,</span> <span class="pre">dim)</span></code></p></li>
<li><p>Attention distribtutions for each query
<code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">tgt_len,</span> <span class="pre">src_len)</span></code></p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(FloatTensor, FloatTensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.modules.GlobalAttention.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h_t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_s</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/global_attention.html#GlobalAttention.score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.GlobalAttention.score" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>h_t</strong> (<em>FloatTensor</em>) – sequence of queries <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">tgt_len,</span> <span class="pre">dim)</span></code></p></li>
<li><p><strong>h_s</strong> (<em>FloatTensor</em>) – sequence of sources <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">src_len,</span> <span class="pre">dim</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>raw attention scores (unnormalized) for each src index</dt><dd><p><code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">tgt_len,</span> <span class="pre">src_len)</span></code></p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>FloatTensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.modules.MultiHeadedAttention">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.modules.</span></span><span class="sig-name descname"><span class="pre">MultiHeadedAttention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">head_count</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_decoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_relative_positions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relative_positions_buckets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rotary_interleave</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rotary_theta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rotary_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">self_attn_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_qkvbias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_kv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_ckpting</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel_gpu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/multi_headed_attn.html#MultiHeadedAttention"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.MultiHeadedAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Multi-Head Attention module from “Attention is All You Need”
<span id="id9">[<a class="reference internal" href="ref.html#id32" title="Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. CoRR, 2017. URL: http://arxiv.org/abs/1706.03762, arXiv:1706.03762.">VSP+17</a>]</span>.</p>
<p>Similar to standard <cite>dot</cite> attention but uses
multiple attention distributions simulataneously
to select relevant items.</p>
<div class="mermaid">
            graph BT
   A[key]
   B[value]
   C[query]
   O[output]
   subgraph Attn
     D[Attn 1]
     E[Attn 2]
     F[Attn N]
   end
   A --&gt; D
   C --&gt; D
   A --&gt; E
   C --&gt; E
   A --&gt; F
   C --&gt; F
   D --&gt; O
   E --&gt; O
   F --&gt; O
   B --&gt; O
        </div><p>Also includes several additional tricks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>head_count</strong> (<em>int</em>) – number of parallel heads</p></li>
<li><p><strong>model_dim</strong> (<em>int</em>) – the dimension of keys/values/queries,
must be divisible by head_count</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – dropout parameter</p></li>
<li><p><strong>max_relative_positions</strong> (<em>int</em>) – max relative positions</p></li>
<li><p><strong>attn_type</strong> – “self” or “context”</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.modules.MultiHeadedAttention.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">query</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sliding_window</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_attn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">self_attn_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/onmt/modules/multi_headed_attn.html#MultiHeadedAttention.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.MultiHeadedAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the context vector and the attention vectors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key</strong> (<em>Tensor</em>) – set of <cite>key_len</cite>
key vectors <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">key_len,</span> <span class="pre">dim)</span></code></p></li>
<li><p><strong>value</strong> (<em>Tensor</em>) – set of <cite>key_len</cite>
value vectors <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">key_len,</span> <span class="pre">dim)</span></code></p></li>
<li><p><strong>query</strong> (<em>Tensor</em>) – set of <cite>query_len</cite>
query vectors  <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">query_len,</span> <span class="pre">dim)</span></code></p></li>
<li><p><strong>mask</strong> – binary mask 1/0 indicating which keys have
zero / non-zero attention <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">query_len,</span> <span class="pre">key_len)</span></code></p></li>
<li><p><strong>step</strong> (<em>int</em>) – decoding step (used for Rotary embedding)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>output context vectors <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">query_len,</span> <span class="pre">dim)</span></code></p></li>
<li><p>Attention vector in heads <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">head,</span> <span class="pre">query_len,</span> <span class="pre">key_len)</span></code>.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(Tensor, Tensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.modules.AverageAttention">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.modules.</span></span><span class="sig-name descname"><span class="pre">AverageAttention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aan_useffn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_ffn_activation_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'relu'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/average_attn.html#AverageAttention"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.AverageAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Average Attention module from
“Accelerating Neural Transformer via an Average Attention Network”
<span id="id10">[<a class="reference internal" href="ref.html#id36" title="Biao Zhang, Deyi Xiong, and Jinsong Su. Accelerating neural transformer via an average attention network. CoRR, 2018. URL: http://arxiv.org/abs/1805.00631, arXiv:1805.00631.">ZXS18</a>]</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_dim</strong> (<em>int</em>) – the dimension of keys/values/queries,
must be divisible by head_count</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – dropout parameter</p></li>
<li><p><strong>pos_ffn_activation_fn</strong> (<em>ActivationFunction</em>) – activation function choice for PositionwiseFeedForward layer</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.modules.AverageAttention.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/average_attn.html#AverageAttention.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.AverageAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>layer_in</strong> (<em>FloatTensor</em>) – <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">t_len,</span> <span class="pre">dim)</span></code></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>gating_out <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">tlen,</span> <span class="pre">dim)</span></code></p></li>
<li><dl class="simple">
<dt>average_out average attention</dt><dd><p><code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">input_len,</span> <span class="pre">dim)</span></code></p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(FloatTensor, FloatTensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.modules.ConvMultiStepAttention">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.modules.</span></span><span class="sig-name descname"><span class="pre">ConvMultiStepAttention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/conv_multi_step_attention.html#ConvMultiStepAttention"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.ConvMultiStepAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Conv attention takes a key matrix, a value matrix and a query vector.
Attention weight is calculated by key matrix with the query vector
and sum on the value matrix. And the same operation is applied
in each decode conv layer.</p>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.modules.ConvMultiStepAttention.apply_mask">
<span class="sig-name descname"><span class="pre">apply_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mask</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/conv_multi_step_attention.html#ConvMultiStepAttention.apply_mask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.ConvMultiStepAttention.apply_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply mask</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.modules.ConvMultiStepAttention.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_target_emb</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_from_dec</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_out_top</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_out_combine</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/conv_multi_step_attention.html#ConvMultiStepAttention.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.ConvMultiStepAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_target_emb</strong> – target emb tensor
<code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">channel,</span> <span class="pre">height,</span> <span class="pre">width)</span></code></p></li>
<li><p><strong>input_from_dec</strong> – output of dec conv
<code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">channel,</span> <span class="pre">height,</span> <span class="pre">width)</span></code></p></li>
<li><p><strong>encoder_out_top</strong> – the key matrix for calc of attention weight,
which is the top output of encode conv</p></li>
<li><p><strong>encoder_out_combine</strong> – the value matrix for the attention-weighted sum,
which is the combination of base emb and top output of encode</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.modules.CopyGenerator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.modules.</span></span><span class="sig-name descname"><span class="pre">CopyGenerator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_idx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/copy_generator.html#CopyGenerator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.CopyGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>An implementation of pointer-generator networks
<span id="id11">[<a class="reference internal" href="ref.html#id35" title="Abigail See, Peter J. Liu, and Christopher D. Manning. Get to the point: summarization with pointer-generator networks. CoRR, 2017. URL: http://arxiv.org/abs/1704.04368, arXiv:1704.04368.">SLM17</a>]</span>.</p>
<p>These networks consider copying words
directly from the source sequence.</p>
<p>The copy generator is an extended version of the standard
generator that computes three values.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(p_{softmax}\)</span> the standard softmax over <cite>tgt_dict</cite></p></li>
<li><p><span class="math notranslate nohighlight">\(p(z)\)</span> the probability of copying a word from
the source</p></li>
<li><p><span class="math notranslate nohighlight">\(p_{copy}\)</span> the probility of copying a particular word.
taken from the attention distribution directly.</p></li>
</ul>
<p>The model returns a distribution over the extend dictionary,
computed as</p>
<p><span class="math notranslate nohighlight">\(p(w) = p(z=1)  p_{copy}(w)  +  p(z=0)  p_{softmax}(w)\)</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<em>int</em>) – size of input representation</p></li>
<li><p><strong>output_size</strong> (<em>int</em>) – size of output vocabulary</p></li>
<li><p><strong>pad_idx</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.modules.CopyGenerator.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_map</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/copy_generator.html#CopyGenerator.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.CopyGenerator.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute a distribution over the target dictionary
extended by the dynamic dictionary implied by copying
source words.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden</strong> (<em>FloatTensor</em>) – hidden output <code class="docutils literal notranslate"><span class="pre">(batch</span> <span class="pre">x</span> <span class="pre">tlen,</span> <span class="pre">input_size)</span></code></p></li>
<li><p><strong>attn</strong> (<em>FloatTensor</em>) – attn for each <code class="docutils literal notranslate"><span class="pre">(batch</span> <span class="pre">x</span> <span class="pre">tlen,</span> <span class="pre">slen)</span></code></p></li>
<li><p><strong>src_map</strong> (<em>FloatTensor</em>) – A sparse indicator matrix mapping each source word to
its index in the “extended” vocab containing.
<code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">src_len,</span> <span class="pre">extra_words)</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.modules.structured_attention.MatrixTree">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.modules.structured_attention.</span></span><span class="sig-name descname"><span class="pre">MatrixTree</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/structured_attention.html#MatrixTree"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.structured_attention.MatrixTree" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Implementation of the matrix-tree theorem for computing marginals
of non-projective dependency parsing. This attention layer is used
in the paper “Learning Structured Text Representations”
<span id="id12">[<a class="reference internal" href="ref.html#id2" title="Yang Liu and Mirella Lapata. Learning structured text representations. CoRR, 2017. URL: http://arxiv.org/abs/1705.09207, arXiv:1705.09207.">LL17</a>]</span>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.modules.structured_attention.MatrixTree.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/modules/structured_attention.html#MatrixTree.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.modules.structured_attention.MatrixTree.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="onmt.translation.html" class="btn btn-neutral float-right" title="Translation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="onmt.html" class="btn btn-neutral float-left" title="Framework" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017-2023, OpenNMT

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>