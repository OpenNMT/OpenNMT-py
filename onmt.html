

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="EN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="EN" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Framework &mdash; OpenNMT-py  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
        <script>mermaid.initialize({startOnLoad:true});</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/theme_overrides.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Modules" href="onmt.modules.html" />
    <link rel="prev" title="Server" href="options/server.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> OpenNMT-py
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="main.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes.html">Versions</a></li>
<li class="toctree-l1"><a class="reference internal" href="CONTRIBUTING.html">Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="ref.html">References</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Frequently Asked Questions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html">How do I use my v2 models in v3 ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-do-i-train-the-transformer-model">How do I train the Transformer model?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#performance-tips">Performance tips</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#position-encoding-absolute-vs-relative-vs-rotary-embeddings-vs-alibi">Position encoding: Absolute vs Relative vs Rotary Embeddings vs Alibi</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#do-you-support-multi-gpu">Do you support multi-gpu?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-do-i-use-pretrained-embeddings-e-g-glove">How do I use Pretrained embeddings (e.g. GloVe)?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-can-i-ensemble-models-at-inference">How can I ensemble Models at inference?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-can-i-weight-different-corpora-at-training">How can I weight different corpora at training?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#what-special-tokens-does-opennmt-py-use">What special tokens does OpenNMT-py use?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-can-i-apply-on-the-fly-tokenization-and-subword-regularization-when-training">How can I apply on-the-fly tokenization and subword regularization when training?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#what-are-the-readily-available-on-the-fly-data-transforms">What are the readily available on-the-fly data transforms?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-can-i-create-custom-on-the-fly-data-transforms">How can I create custom on-the-fly data transforms?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-to-use-lora-and-8bit-loading-to-finetune-a-big-model">How to use LoRa and 8bit loading to finetune a big model ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-to-use-gradient-checkpointing-when-dealing-with-a-big-model">How to use gradient checkpointing when dealing with a big model ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#can-i-get-word-alignments-while-translating">Can I get word alignments while translating?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-can-i-update-a-checkpoint-s-vocabulary">How can I update a checkpoint’s vocabulary?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-can-i-use-source-word-features">How can I use source word features?</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html#how-can-i-set-up-a-translation-server">How can I set up a translation server ?</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="examples/wmt17/Translation.html">Translation WMT17 en-de</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/wiki_103/LanguageModelGeneration.html">Language Model Wiki-103</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/summary/Summarization.html">Summarization CNN/DM</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/ggnn/GGNN.html">Gated Graph Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/replicate_vicuna/ReplicateVicuna.html">Supervised Finetuning of llama 7B to replicate Vicuna</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Scripts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="options/build_vocab.html">Build Vocab</a></li>
<li class="toctree-l1"><a class="reference internal" href="options/train.html">Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="options/translate.html">Translate</a></li>
<li class="toctree-l1"><a class="reference internal" href="options/server.html">Server</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Framework</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#model">Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#onmt.models.BaseModel"><code class="docutils literal notranslate"><span class="pre">BaseModel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.models.BaseModel.forward"><code class="docutils literal notranslate"><span class="pre">BaseModel.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.models.BaseModel.load_state_dict"><code class="docutils literal notranslate"><span class="pre">BaseModel.load_state_dict()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.models.NMTModel"><code class="docutils literal notranslate"><span class="pre">NMTModel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.models.NMTModel.count_parameters"><code class="docutils literal notranslate"><span class="pre">NMTModel.count_parameters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.models.NMTModel.forward"><code class="docutils literal notranslate"><span class="pre">NMTModel.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.models.LanguageModel"><code class="docutils literal notranslate"><span class="pre">LanguageModel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.models.LanguageModel.count_parameters"><code class="docutils literal notranslate"><span class="pre">LanguageModel.count_parameters()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.models.LanguageModel.forward"><code class="docutils literal notranslate"><span class="pre">LanguageModel.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#trainer">Trainer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#onmt.trainer.Trainer"><code class="docutils literal notranslate"><span class="pre">Trainer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.trainer.Trainer.train"><code class="docutils literal notranslate"><span class="pre">Trainer.train()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.trainer.Trainer.validate"><code class="docutils literal notranslate"><span class="pre">Trainer.validate()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.utils.Statistics"><code class="docutils literal notranslate"><span class="pre">Statistics</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.Statistics.accuracy"><code class="docutils literal notranslate"><span class="pre">Statistics.accuracy()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.Statistics.all_gather_stats"><code class="docutils literal notranslate"><span class="pre">Statistics.all_gather_stats()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.Statistics.all_gather_stats_list"><code class="docutils literal notranslate"><span class="pre">Statistics.all_gather_stats_list()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.Statistics.elapsed_time"><code class="docutils literal notranslate"><span class="pre">Statistics.elapsed_time()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.Statistics.log_tensorboard"><code class="docutils literal notranslate"><span class="pre">Statistics.log_tensorboard()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.Statistics.output"><code class="docutils literal notranslate"><span class="pre">Statistics.output()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.Statistics.ppl"><code class="docutils literal notranslate"><span class="pre">Statistics.ppl()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.Statistics.update"><code class="docutils literal notranslate"><span class="pre">Statistics.update()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.Statistics.xent"><code class="docutils literal notranslate"><span class="pre">Statistics.xent()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#loss">Loss</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#onmt.utils.loss.LossCompute"><code class="docutils literal notranslate"><span class="pre">LossCompute</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.loss.LossCompute.forward"><code class="docutils literal notranslate"><span class="pre">LossCompute.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.loss.LossCompute.from_opts"><code class="docutils literal notranslate"><span class="pre">LossCompute.from_opts()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#optimizer">Optimizer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#onmt.utils.Optimizer"><code class="docutils literal notranslate"><span class="pre">Optimizer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.Optimizer.amp"><code class="docutils literal notranslate"><span class="pre">Optimizer.amp</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.Optimizer.backward"><code class="docutils literal notranslate"><span class="pre">Optimizer.backward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.Optimizer.from_opt"><code class="docutils literal notranslate"><span class="pre">Optimizer.from_opt()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.Optimizer.learning_rate"><code class="docutils literal notranslate"><span class="pre">Optimizer.learning_rate()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.Optimizer.step"><code class="docutils literal notranslate"><span class="pre">Optimizer.step()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.Optimizer.training_step"><code class="docutils literal notranslate"><span class="pre">Optimizer.training_step</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.Optimizer.zero_grad"><code class="docutils literal notranslate"><span class="pre">Optimizer.zero_grad()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.utils.AdaFactor"><code class="docutils literal notranslate"><span class="pre">AdaFactor</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.AdaFactor.step"><code class="docutils literal notranslate"><span class="pre">AdaFactor.step()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onmt.utils.FusedAdam"><code class="docutils literal notranslate"><span class="pre">FusedAdam</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#onmt.utils.FusedAdam.step"><code class="docutils literal notranslate"><span class="pre">FusedAdam.step()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="onmt.modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="onmt.translation.html">Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="onmt.translate.translation_server.html">Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="onmt.inputters.html">Data Loaders</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Legacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="legacy/FAQ.html">FAQ (Legacy version)</a></li>
<li class="toctree-l1"><a class="reference internal" href="legacy/im2text.html">Image to Text</a></li>
<li class="toctree-l1"><a class="reference internal" href="legacy/speech2text.html">Speech to Text</a></li>
<li class="toctree-l1"><a class="reference internal" href="legacy/vid2text.html">Video to Text</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">OpenNMT-py</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Framework</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/onmt.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="framework">
<h1>Framework<a class="headerlink" href="#framework" title="Permalink to this heading">¶</a></h1>
<section id="model">
<h2>Model<a class="headerlink" href="#model" title="Permalink to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="onmt.models.BaseModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.models.</span></span><span class="sig-name descname"><span class="pre">BaseModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/models/model.html#BaseModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.models.BaseModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Core trainable object in OpenNMT. Implements a trainable interface
for a simple, generic encoder / decoder or decoder only model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder</strong> (<a class="reference internal" href="onmt.modules.html#onmt.encoders.EncoderBase" title="onmt.encoders.EncoderBase"><em>onmt.encoders.EncoderBase</em></a>) – an encoder object</p></li>
<li><p><strong>decoder</strong> (<a class="reference internal" href="onmt.modules.html#onmt.decoders.DecoderBase" title="onmt.decoders.DecoderBase"><em>onmt.decoders.DecoderBase</em></a>) – a decoder object</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.models.BaseModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tgt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bptt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_align</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/models/model.html#BaseModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.models.BaseModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward propagate a <cite>src</cite> and <cite>tgt</cite> pair for training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> (<em>Tensor</em>) – A source sequence passed to encoder.
Typically for input this will be a padded <cite>LongTensor</cite>
of size <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">len,</span> <span class="pre">features)</span></code>. However, may be an
image or other generic input depending on encoder.</p></li>
<li><p><strong>tgt</strong> (<em>LongTensor</em>) – A target sequence passed to decoder.
Size <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">tgt_len,</span> <span class="pre">features)</span></code>.</p></li>
<li><p><strong>src_len</strong> (<em>LongTensor</em>) – The src lengths, pre-padding <code class="docutils literal notranslate"><span class="pre">(batch,)</span></code>.</p></li>
<li><p><strong>bptt</strong> (<em>Boolean</em>) – A flag indicating if truncated bptt is set.
If bptt is false then init decoder state.</p></li>
<li><p><strong>with_align</strong> (<em>Boolean</em>) – A flag indicating whether output alignment,
Only valid for transformer decoder.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>decoder output <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">tgt_len,</span> <span class="pre">hidden)</span></code></p></li>
<li><p>dictionary of attention weights <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">tgt_len,</span> <span class="pre">src_len)</span></code></p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(FloatTensor, dict[str, FloatTensor])</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.models.BaseModel.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">precision</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.float32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">device(type='cpu')</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/models/model.html#BaseModel.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.models.BaseModel.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Custom state_dict loading to enable moving module on device as they are loaded</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>checkpoint</strong> – </p></li>
<li><p><strong>precision</strong> – </p></li>
<li><p><strong>device</strong> – </p></li>
<li><p><strong>strict</strong> – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>Model</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.models.NMTModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.models.</span></span><span class="sig-name descname"><span class="pre">NMTModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/models/model.html#NMTModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.models.NMTModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#onmt.models.BaseModel" title="onmt.models.model.BaseModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModel</span></code></a></p>
<p>NMTModel Class
See <a class="reference internal" href="#onmt.models.BaseModel" title="onmt.models.BaseModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModel</span></code></a> for options.</p>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.models.NMTModel.count_parameters">
<span class="sig-name descname"><span class="pre">count_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log=&lt;built-in</span> <span class="pre">function</span> <span class="pre">print&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/models/model.html#NMTModel.count_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.models.NMTModel.count_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Count number of parameters in model (&amp; print with <cite>log</cite> callback).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>encoder side parameter count</p></li>
<li><p>decoder side parameter count</p></li>
</ul>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>(int, int)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.models.NMTModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tgt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bptt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_align</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/models/model.html#NMTModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.models.NMTModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>An NMTModel forward the src side to the encoder.
Then the output of encoder <code class="docutils literal notranslate"><span class="pre">enc_out</span></code> is forwarded to the
decoder along with the target excluding the last token.
The decoder state is initiliazed with:
* enc_final_hs in the case of RNNs
* enc_out + enc_final_hs in the case of CNNs
* src in the case of Transformer</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.models.LanguageModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.models.</span></span><span class="sig-name descname"><span class="pre">LanguageModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/models/model.html#LanguageModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.models.LanguageModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#onmt.models.BaseModel" title="onmt.models.model.BaseModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModel</span></code></a></p>
<p>NMTModel Class
Currently TransformerLMDecoder is the only LM decoder implemented</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>decoder</strong> (<em>onmt.decoders.TransformerLMDecoder</em>) – a transformer decoder</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.models.LanguageModel.count_parameters">
<span class="sig-name descname"><span class="pre">count_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log=&lt;built-in</span> <span class="pre">function</span> <span class="pre">print&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/models/model.html#LanguageModel.count_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.models.LanguageModel.count_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Count number of parameters in model (&amp; print with <cite>log</cite> callback).</p>
<dl class="simple">
<dt>Returns: (int, int)</dt><dd><p>encoder side parameter count
decoder side parameter count</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.models.LanguageModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tgt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bptt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_align</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/models/model.html#LanguageModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.models.LanguageModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>A LanguageModel forward the src side to the decoder along
with the source lengths vector. It is a decoder only LM (cf GPT-2)</p>
</dd></dl>

</dd></dl>

</section>
<section id="trainer">
<h2>Trainer<a class="headerlink" href="#trainer" title="Permalink to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="onmt.trainer.Trainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.trainer.</span></span><span class="sig-name descname"><span class="pre">Trainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring_preparator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_scorers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_scorers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trunc_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sents'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accum_count</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[1]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accum_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_gpu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gpu_rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_eval_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">report_manager</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_align</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_saver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average_every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'fp32'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">earlystopper</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0.3]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0.1]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0]</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/trainer.html#Trainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.trainer.Trainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class that controls the training process.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="#onmt.models.NMTModel" title="onmt.models.model.NMTModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">onmt.models.model.NMTModel</span></code></a>) – model to train</p></li>
<li><p><strong>train_loss</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">onmt.utils.loss.LossComputeBase</span></code>) – training loss computation</p></li>
<li><p><strong>valid_loss</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">onmt.utils.loss.LossComputeBase</span></code>) – training loss computation</p></li>
<li><p><strong>scoring_preparator</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">onmt.translate.utils.ScoringPreparator</span></code>) – preparator for the calculation of metrics via the
training_eval_handler method</p></li>
<li><p><strong>train_scorers</strong> (<em>dict</em>) – keeps in memory the current values
of the training metrics</p></li>
<li><p><strong>valid_scorers</strong> (<em>dict</em>) – keeps in memory the current values
of the validation metrics</p></li>
<li><p><strong>optim</strong> (<a class="reference internal" href="#onmt.utils.Optimizer" title="onmt.utils.optimizers.Optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">onmt.utils.optimizers.Optimizer</span></code></a>) – the optimizer responsible for update</p></li>
<li><p><strong>trunc_size</strong> (<em>int</em>) – length of truncated back propagation
through time</p></li>
<li><p><strong>accum_count</strong> (<em>list</em>) – accumulate gradients this many times.</p></li>
<li><p><strong>accum_steps</strong> (<em>list</em>) – steps for accum gradients changes.</p></li>
<li><p><strong>n_gpu</strong> (<em>int</em>) – number of gpu.</p></li>
<li><p><strong>gpu_rank</strong> (<em>int</em>) – ordinal rank of the gpu in the list.</p></li>
<li><p><strong>train_eval_steps</strong> (<em>int</em>) – process a validation every x steps.</p></li>
<li><p><strong>report_manager</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">onmt.utils.ReportMgrBase</span></code>) – the object that creates reports, or None</p></li>
<li><p><strong>with_align</strong> (<em>bool</em>) – whether to jointly lear alignment
(Transformer)</p></li>
<li><p><strong>model_saver</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">onmt.models.ModelSaverBase</span></code>) – the saver is
used to save a checkpoint.
Thus nothing will be saved if this parameter is None.</p></li>
<li><p><strong>average_decay</strong> (<em>float</em>) – cf opt.average_decay</p></li>
<li><p><strong>average_every</strong> (<em>int</em>) – average model every x steps.</p></li>
<li><p><strong>model_dtype</strong> (<em>str</em>) – fp32 or fp16.</p></li>
<li><p><strong>earlystopper</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">onmt.utils.EarlyStopping</span></code>) – add early
stopping mecanism</p></li>
<li><p><strong>dropout</strong> (<em>float</em>) – dropout value in RNN or FF layers.</p></li>
<li><p><strong>attention_dropout</strong> (<em>float</em>) – dropaout in attention layers.</p></li>
<li><p><strong>dropout_steps</strong> (<em>list</em>) – dropout values scheduling in steps.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.trainer.Trainer.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_iter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_checkpoint_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/trainer.html#Trainer.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.trainer.Trainer.train" title="Permalink to this definition">¶</a></dt>
<dd><p>The main training loop by iterating over <code class="docutils literal notranslate"><span class="pre">train_iter</span></code> and possibly
running validation on <code class="docutils literal notranslate"><span class="pre">valid_iter</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_iter</strong> – An iterator that returns the next training batch.</p></li>
<li><p><strong>train_steps</strong> – Run training for this many iterations.</p></li>
<li><p><strong>save_checkpoint_steps</strong> – Save a checkpoint every this many
iterations.</p></li>
<li><p><strong>valid_iter</strong> – A generator that returns the next validation batch.</p></li>
<li><p><strong>valid_steps</strong> – Run evaluation every this many iterations.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>training loss statistics</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>:obj:<code class="docutils literal notranslate"><span class="pre">nmt.Statistics</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.trainer.Trainer.validate">
<span class="sig-name descname"><span class="pre">validate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">valid_iter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">moving_average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/trainer.html#Trainer.validate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.trainer.Trainer.validate" title="Permalink to this definition">¶</a></dt>
<dd><p>Validate model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>valid_iter</strong> – validate data iterator</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>validation loss statistics</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>:obj:<code class="docutils literal notranslate"><span class="pre">nmt.Statistics</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.utils.Statistics">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.utils.</span></span><span class="sig-name descname"><span class="pre">Statistics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_batchs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_sents</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_words</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_correct</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">computed_metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/statistics.html#Statistics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.Statistics" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Accumulator for loss statistics.
Currently calculates:</p>
<ul class="simple">
<li><p>accuracy</p></li>
<li><p>perplexity</p></li>
<li><p>elapsed time</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.Statistics.accuracy">
<span class="sig-name descname"><span class="pre">accuracy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/statistics.html#Statistics.accuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.Statistics.accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>compute accuracy</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.Statistics.all_gather_stats">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">all_gather_stats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/statistics.html#Statistics.all_gather_stats"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.Statistics.all_gather_stats" title="Permalink to this definition">¶</a></dt>
<dd><p>Gather a <cite>Statistics</cite> object accross multiple process/nodes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>stat</strong><strong>(</strong> – obj:Statistics): the statistics object to gather
accross all processes/nodes</p></li>
<li><p><strong>max_size</strong> (<em>int</em>) – max buffer size to use</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>Statistics</cite>, the update stats object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.Statistics.all_gather_stats_list">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">all_gather_stats_list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stat_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/statistics.html#Statistics.all_gather_stats_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.Statistics.all_gather_stats_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Gather a <cite>Statistics</cite> list accross all processes/nodes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>stat_list</strong> (list([<cite>Statistics</cite>])) – list of statistics objects to
gather accross all processes/nodes</p></li>
<li><p><strong>max_size</strong> (<em>int</em>) – max buffer size to use</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>list of updated stats</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>our_stats(list([<cite>Statistics</cite>]))</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.Statistics.elapsed_time">
<span class="sig-name descname"><span class="pre">elapsed_time</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/statistics.html#Statistics.elapsed_time"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.Statistics.elapsed_time" title="Permalink to this definition">¶</a></dt>
<dd><p>compute elapsed time</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.Statistics.log_tensorboard">
<span class="sig-name descname"><span class="pre">log_tensorboard</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">writer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/statistics.html#Statistics.log_tensorboard"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.Statistics.log_tensorboard" title="Permalink to this definition">¶</a></dt>
<dd><p>display statistics to tensorboard</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.Statistics.output">
<span class="sig-name descname"><span class="pre">output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/statistics.html#Statistics.output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.Statistics.output" title="Permalink to this definition">¶</a></dt>
<dd><p>Write out statistics to stdout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>step</strong> (<em>int</em>) – current step</p></li>
<li><p><strong>n_batch</strong> (<em>int</em>) – total batches</p></li>
<li><p><strong>start</strong> (<em>int</em>) – start time of step.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.Statistics.ppl">
<span class="sig-name descname"><span class="pre">ppl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/statistics.html#Statistics.ppl"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.Statistics.ppl" title="Permalink to this definition">¶</a></dt>
<dd><p>compute perplexity</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.Statistics.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update_n_src_words</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/statistics.html#Statistics.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.Statistics.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update statistics by suming values with another <cite>Statistics</cite> object</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>stat</strong> – another statistic object</p></li>
<li><p><strong>update_n_src_words</strong> (<em>bool</em>) – whether to update (sum) <cite>n_src_words</cite>
or not</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.Statistics.xent">
<span class="sig-name descname"><span class="pre">xent</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/statistics.html#Statistics.xent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.Statistics.xent" title="Permalink to this definition">¶</a></dt>
<dd><p>compute cross entropy</p>
</dd></dl>

</dd></dl>

</section>
<section id="loss">
<h2>Loss<a class="headerlink" href="#loss" title="Permalink to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="onmt.utils.loss.LossCompute">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.utils.loss.</span></span><span class="sig-name descname"><span class="pre">LossCompute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">criterion</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy_attn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda_coverage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda_align</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tgt_shift_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lm_generator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lm_prior_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lm_prior_tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lm_prior_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/loss.html#LossCompute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.loss.LossCompute" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Class for managing efficient loss computation. Handles
accumulating multiple loss computations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>criterion</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">nn.</span> <span class="pre">loss</span> <span class="pre">function</span></code>) – NLLoss or customed loss</p></li>
<li><p><strong>generator</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">nn.Module</span></code>) – </p></li>
<li><p><strong>copy_attn</strong> (<em>bool</em>) – whether copy attention mechanism is on/off</p></li>
<li><p><strong>lambda_coverage</strong> – Hyper-param to apply coverage attention if any</p></li>
<li><p><strong>lambda_align</strong> – Hyper-param for alignment loss</p></li>
<li><p><strong>tgt_shift_index</strong> (<em>int</em>) – 1 for NMT, 0 for LM</p></li>
<li><p><strong>vocab</strong> – target vocab (for copy attention score calculation)
module that maps the output of the decoder to a
distribution over the target vocabulary.</p></li>
<li><p><strong>lm_generator</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">ctranslate2.Generator</span></code>) – LM Generator</p></li>
<li><p><strong>lm_prior_lambda</strong> (<em>float</em>) – weight of LM model in loss</p></li>
<li><p><strong>lm_prior_tau</strong> (<em>float</em>) – scaler for LM loss</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.loss.LossCompute.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attns</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trunc_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trunc_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/loss.html#LossCompute.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.loss.LossCompute.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the forward loss, supports truncated BPTT for long
sequences by taking a range in the decoder output sequence to
back propagate in.
Range is from <cite>(trunc_start, trunc_start + trunc_size)</cite>.
Truncation is an approximate efficiency trick to relieve the
memory required in the RNN buffers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>batch</em>) – batch of labeled examples</p></li>
<li><p><strong>output</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">FloatTensor</span></code>) – output of decoder model <code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">tgt_len,</span> <span class="pre">hidden)</span></code></p></li>
<li><p><strong>attns</strong> (<em>dict</em>) – dictionary of attention weights
<code class="docutils literal notranslate"><span class="pre">(batch,</span> <span class="pre">tgt_len,</span> <span class="pre">src_len)</span></code></p></li>
<li><p><strong>trunc_start</strong> (<em>int</em>) – starting position of truncation window</p></li>
<li><p><strong>trunc_size</strong> (<em>int</em>) – length of truncation window</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple with the loss and a <a class="reference internal" href="#onmt.utils.Statistics" title="onmt.utils.Statistics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">onmt.utils.Statistics</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.loss.LossCompute.from_opts">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_opts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/loss.html#LossCompute.from_opts"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.loss.LossCompute.from_opts" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a subclass which wraps around an nn.Module subclass
(such as nn.NLLLoss) which defines the loss criterion. The LossCompute
object passes relevant data to a Statistics object which handles
training/validation logging.
The Criterion and LossCompute options are triggered by opt settings.</p>
</dd></dl>

</dd></dl>

</section>
<section id="optimizer">
<h2>Optimizer<a class="headerlink" href="#optimizer" title="Permalink to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="onmt.utils.Optimizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.utils.</span></span><span class="sig-name descname"><span class="pre">Optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate_decay_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_grad_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/optimizers.html#Optimizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.Optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Controller class for optimization. Mostly a thin
wrapper for <cite>optim</cite>, but also useful for implementing
rate scheduling beyond what is currently available.
Also implements necessary methods for training RNNs such
as grad manipulations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> – A <code class="docutils literal notranslate"><span class="pre">torch.optim.Optimizer</span></code> instance.</p></li>
<li><p><strong>learning_rate</strong> – The initial learning rate.</p></li>
<li><p><strong>learning_rate_decay_fn</strong> – An optional callable taking the current step
as argument and return a learning rate scaling factor.</p></li>
<li><p><strong>max_grad_norm</strong> – Clip gradients to this global norm.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="onmt.utils.Optimizer.amp">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">amp</span></span><a class="headerlink" href="#onmt.utils.Optimizer.amp" title="Permalink to this definition">¶</a></dt>
<dd><p>True if use torch amp mix precision training.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.Optimizer.backward">
<span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/optimizers.html#Optimizer.backward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.Optimizer.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for backward pass. Some optimizer requires ownership of the
backward pass.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.Optimizer.from_opt">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_opt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/optimizers.html#Optimizer.from_opt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.Optimizer.from_opt" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds the optimizer from options.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cls</strong> – The <code class="docutils literal notranslate"><span class="pre">Optimizer</span></code> class to instantiate.</p></li>
<li><p><strong>model</strong> – The model to optimize.</p></li>
<li><p><strong>opt</strong> – The dict of user options.</p></li>
<li><p><strong>checkpoint</strong> – An optional checkpoint to load states from.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An <code class="docutils literal notranslate"><span class="pre">Optimizer</span></code> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.Optimizer.learning_rate">
<span class="sig-name descname"><span class="pre">learning_rate</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/optimizers.html#Optimizer.learning_rate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.Optimizer.learning_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the current learning rate.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.Optimizer.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/optimizers.html#Optimizer.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.Optimizer.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the model parameters based on current gradients.</p>
<p>Optionally, will employ gradient modification or update learning
rate.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="onmt.utils.Optimizer.training_step">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">training_step</span></span><a class="headerlink" href="#onmt.utils.Optimizer.training_step" title="Permalink to this definition">¶</a></dt>
<dd><p>The current training step.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.Optimizer.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">set_to_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/optimizers.html#Optimizer.zero_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.Optimizer.zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Zero the gradients of optimized parameters.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.utils.AdaFactor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.utils.</span></span><span class="sig-name descname"><span class="pre">AdaFactor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.999</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cliping_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_constant_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_factorization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ams_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/optimizers.html#AdaFactor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.AdaFactor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.AdaFactor.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/optimizers.html#AdaFactor.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.AdaFactor.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a single optimization step (parameter update).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>closure</strong> (<em>Callable</em>) – A closure that reevaluates the model and
returns the loss. Optional for most optimizers.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Unless otherwise specified, this function should not modify the
<code class="docutils literal notranslate"><span class="pre">.grad</span></code> field of the parameters.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="onmt.utils.FusedAdam">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">onmt.utils.</span></span><span class="sig-name descname"><span class="pre">FusedAdam</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_correction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">betas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.9,</span> <span class="pre">0.999)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps_inside_sqrt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_grad_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amsgrad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/optimizers.html#FusedAdam"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.FusedAdam" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></p>
<dl class="simple">
<dt>Implements Adam algorithm. Currently GPU-only.</dt><dd><p>Requires Apex to be installed via
<code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">setup.py</span> <span class="pre">install</span> <span class="pre">--cuda_ext</span> <span class="pre">--cpp_ext</span></code>.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>iterable</em>) – iterable of parameters to optimize or dicts defining
parameter groups.</p></li>
<li><p><strong>lr</strong> (<em>float</em><em>, </em><em>optional</em>) – learning rate. (default: 1e-3)</p></li>
<li><p><strong>betas</strong> (<em>Tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>, </em><em>optional</em>) – coefficients used for computing
running averages of gradient and its square.
(default: (0.9, 0.999))</p></li>
<li><p><strong>eps</strong> (<em>float</em><em>, </em><em>optional</em>) – term added to the denominator to improve
numerical stability. (default: 1e-8)</p></li>
<li><p><strong>weight_decay</strong> (<em>float</em><em>, </em><em>optional</em>) – weight decay (L2 penalty) (default: 0)</p></li>
<li><p><strong>amsgrad</strong> (<em>boolean</em><em>, </em><em>optional</em>) – whether to use the AMSGrad variant of this
algorithm from the paper ‘On the Convergence of Adam and Beyond’
(default: False) NOT SUPPORTED in FusedAdam!</p></li>
<li><p><strong>eps_inside_sqrt</strong> (<em>boolean</em><em>, </em><em>optional</em>) – in the ‘update parameters’ step,
adds eps to the bias-corrected second moment estimate before
evaluating square root instead of adding it to the square root of
second moment estimate as in the original paper. (default: False)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="onmt.utils.FusedAdam.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_norms</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/onmt/utils/optimizers.html#FusedAdam.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#onmt.utils.FusedAdam.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a single optimization step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>closure</strong> (<em>callable</em><em>, </em><em>optional</em>) – A closure that reevaluates the model
and returns the loss.</p></li>
<li><p><strong>grads</strong> (<em>list</em><em> of </em><em>tensors</em><em>, </em><em>optional</em>) – weight gradient to use for the
optimizer update. If gradients have type torch.half, parameters
are expected to be in type torch.float. (default: None)</p></li>
<li><p><strong>params</strong> (<em>output</em>) – A reduced precision copy
of the updated weights written out in addition to the regular
updated weights. Have to be of same type as gradients.
(default: None)</p></li>
<li><p><strong>scale</strong> (<em>float</em><em>, </em><em>optional</em>) – factor to divide gradient tensor values
by before applying to weights. (default: 1)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="onmt.modules.html" class="btn btn-neutral float-right" title="Modules" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="options/server.html" class="btn btn-neutral float-left" title="Server" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017-2023, OpenNMT

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>