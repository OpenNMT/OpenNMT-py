

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="EN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="EN" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Build Vocab &mdash; OpenNMT-py  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
        <script>mermaid.initialize({startOnLoad:true});</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/theme_overrides.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Train" href="train.html" />
    <link rel="prev" title="Supervised Finetuning of llama 7B to replicate Vicuna" href="../examples/replicate_vicuna/ReplicateVicuna.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> OpenNMT-py
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../main.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changes.html">Versions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CONTRIBUTING.html">Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ref.html">References</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Frequently Asked Questions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html">How do I use my v2 models in v3 ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#how-do-i-train-the-transformer-model">How do I train the Transformer model?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#performance-tips">Performance tips</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#position-encoding-absolute-vs-relative-vs-rotary-embeddings-vs-alibi">Position encoding: Absolute vs Relative vs Rotary Embeddings vs Alibi</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#do-you-support-multi-gpu">Do you support multi-gpu?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#how-do-i-use-pretrained-embeddings-e-g-glove">How do I use Pretrained embeddings (e.g. GloVe)?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#how-can-i-ensemble-models-at-inference">How can I ensemble Models at inference?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#how-can-i-weight-different-corpora-at-training">How can I weight different corpora at training?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#what-special-tokens-does-opennmt-py-use">What special tokens does OpenNMT-py use?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#how-can-i-apply-on-the-fly-tokenization-and-subword-regularization-when-training">How can I apply on-the-fly tokenization and subword regularization when training?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#what-are-the-readily-available-on-the-fly-data-transforms">What are the readily available on-the-fly data transforms?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#how-can-i-create-custom-on-the-fly-data-transforms">How can I create custom on-the-fly data transforms?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#how-to-use-lora-and-8bit-loading-to-finetune-a-big-model">How to use LoRa and 8bit loading to finetune a big model ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#how-to-use-gradient-checkpointing-when-dealing-with-a-big-model">How to use gradient checkpointing when dealing with a big model ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#can-i-get-word-alignments-while-translating">Can I get word alignments while translating?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#how-can-i-update-a-checkpoint-s-vocabulary">How can I update a checkpoint’s vocabulary?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#how-can-i-use-source-word-features">How can I use source word features?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../FAQ.html#how-can-i-set-up-a-translation-server">How can I set up a translation server ?</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples/wmt17/Translation.html">Translation WMT17 en-de</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/wiki_103/LanguageModelGeneration.html">Language Model Wiki-103</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/summary/Summarization.html">Summarization CNN/DM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/ggnn/GGNN.html">Gated Graph Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/replicate_vicuna/ReplicateVicuna.html">Supervised Finetuning of llama 7B to replicate Vicuna</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Scripts</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Build Vocab</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Configuration">Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Data">Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Vocab">Vocab</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Features">Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/InsertMaskBeforePlaceholdersTransform">Transform/InsertMaskBeforePlaceholdersTransform</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Uppercase">Transform/Uppercase</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/InlineTags">Transform/InlineTags</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/BART">Transform/BART</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Terminology">Transform/Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Docify">Transform/Docify</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/InferFeats">Transform/InferFeats</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Filter">Transform/Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Prefix">Transform/Prefix</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Suffix">Transform/Suffix</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/FuzzyMatching">Transform/FuzzyMatching</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Clean">Transform/Clean</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/SwitchOut">Transform/SwitchOut</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Token_Drop">Transform/Token_Drop</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Token_Mask">Transform/Token_Mask</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Subword/Common">Transform/Subword/Common</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Subword/ONMTTOK">Transform/Subword/ONMTTOK</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Transform/Normalize">Transform/Normalize</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Reproducibility">Reproducibility</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="train.html">Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="translate.html">Translate</a></li>
<li class="toctree-l1"><a class="reference internal" href="server.html">Server</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../onmt.html">Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onmt.modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onmt.translation.html">Translation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onmt.translate.translation_server.html">Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onmt.inputters.html">Data Loaders</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Legacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../legacy/FAQ.html">FAQ (Legacy version)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../legacy/im2text.html">Image to Text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../legacy/speech2text.html">Speech to Text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../legacy/vid2text.html">Video to Text</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">OpenNMT-py</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Build Vocab</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/options/build_vocab.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="build-vocab">
<h1>Build Vocab<a class="headerlink" href="#build-vocab" title="Permalink to this heading">¶</a></h1>
<p><p>build_vocab.py</p>
</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">usage</span><span class="p">:</span> <span class="n">build_vocab</span><span class="o">.</span><span class="n">py</span> <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">config</span> <span class="n">CONFIG</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">save_config</span> <span class="n">SAVE_CONFIG</span><span class="p">]</span> <span class="o">-</span><span class="n">data</span>
                      <span class="n">DATA</span> <span class="p">[</span><span class="o">-</span><span class="n">skip_empty_level</span> <span class="p">{</span><span class="n">silent</span><span class="p">,</span><span class="n">warning</span><span class="p">,</span><span class="n">error</span><span class="p">}]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">transforms</span> <span class="p">{</span><span class="n">insert_mask_before_placeholder</span><span class="p">,</span><span class="n">uppercase</span><span class="p">,</span><span class="n">inlinetags</span><span class="p">,</span><span class="n">bart</span><span class="p">,</span><span class="n">terminology</span><span class="p">,</span><span class="n">docify</span><span class="p">,</span><span class="n">inferfeats</span><span class="p">,</span><span class="n">filtertoolong</span><span class="p">,</span><span class="n">prefix</span><span class="p">,</span><span class="n">suffix</span><span class="p">,</span><span class="n">fuzzymatch</span><span class="p">,</span><span class="n">clean</span><span class="p">,</span><span class="n">switchout</span><span class="p">,</span><span class="n">tokendrop</span><span class="p">,</span><span class="n">tokenmask</span><span class="p">,</span><span class="n">sentencepiece</span><span class="p">,</span><span class="n">bpe</span><span class="p">,</span><span class="n">onmt_tokenize</span><span class="p">,</span><span class="n">normalize</span><span class="p">}</span> <span class="p">[{</span><span class="n">insert_mask_before_placeholder</span><span class="p">,</span><span class="n">uppercase</span><span class="p">,</span><span class="n">inlinetags</span><span class="p">,</span><span class="n">bart</span><span class="p">,</span><span class="n">terminology</span><span class="p">,</span><span class="n">docify</span><span class="p">,</span><span class="n">inferfeats</span><span class="p">,</span><span class="n">filtertoolong</span><span class="p">,</span><span class="n">prefix</span><span class="p">,</span><span class="n">suffix</span><span class="p">,</span><span class="n">fuzzymatch</span><span class="p">,</span><span class="n">clean</span><span class="p">,</span><span class="n">switchout</span><span class="p">,</span><span class="n">tokendrop</span><span class="p">,</span><span class="n">tokenmask</span><span class="p">,</span><span class="n">sentencepiece</span><span class="p">,</span><span class="n">bpe</span><span class="p">,</span><span class="n">onmt_tokenize</span><span class="p">,</span><span class="n">normalize</span><span class="p">}</span> <span class="o">...</span><span class="p">]]</span>
                      <span class="o">-</span><span class="n">save_data</span> <span class="n">SAVE_DATA</span> <span class="p">[</span><span class="o">-</span><span class="n">overwrite</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">n_sample</span> <span class="n">N_SAMPLE</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">dump_samples</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">num_threads</span> <span class="n">NUM_THREADS</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">learn_subwords</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">learn_subwords_size</span> <span class="n">LEARN_SUBWORDS_SIZE</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">vocab_sample_queue_size</span> <span class="n">VOCAB_SAMPLE_QUEUE_SIZE</span><span class="p">]</span>
                      <span class="o">-</span><span class="n">src_vocab</span> <span class="n">SRC_VOCAB</span> <span class="p">[</span><span class="o">-</span><span class="n">tgt_vocab</span> <span class="n">TGT_VOCAB</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">share_vocab</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">decoder_start_token</span> <span class="n">DECODER_START_TOKEN</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">default_specials</span> <span class="n">DEFAULT_SPECIALS</span> <span class="p">[</span><span class="n">DEFAULT_SPECIALS</span> <span class="o">...</span><span class="p">]]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">n_src_feats</span> <span class="n">N_SRC_FEATS</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">src_feats_defaults</span> <span class="n">SRC_FEATS_DEFAULTS</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">response_patterns</span> <span class="n">RESPONSE_PATTERNS</span> <span class="p">[</span><span class="n">RESPONSE_PATTERNS</span> <span class="o">...</span><span class="p">]]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">upper_corpus_ratio</span> <span class="n">UPPER_CORPUS_RATIO</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">tags_dictionary_path</span> <span class="n">TAGS_DICTIONARY_PATH</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">tags_corpus_ratio</span> <span class="n">TAGS_CORPUS_RATIO</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">max_tags</span> <span class="n">MAX_TAGS</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">paired_stag</span> <span class="n">PAIRED_STAG</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">paired_etag</span> <span class="n">PAIRED_ETAG</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">isolated_tag</span> <span class="n">ISOLATED_TAG</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">src_delimiter</span> <span class="n">SRC_DELIMITER</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">permute_sent_ratio</span> <span class="n">PERMUTE_SENT_RATIO</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">rotate_ratio</span> <span class="n">ROTATE_RATIO</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">insert_ratio</span> <span class="n">INSERT_RATIO</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">random_ratio</span> <span class="n">RANDOM_RATIO</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">mask_ratio</span> <span class="n">MASK_RATIO</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">mask_length</span> <span class="p">{</span><span class="n">subword</span><span class="p">,</span><span class="n">word</span><span class="p">,</span><span class="n">span</span><span class="o">-</span><span class="n">poisson</span><span class="p">}]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">poisson_lambda</span> <span class="n">POISSON_LAMBDA</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">replace_length</span> <span class="p">{</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">}]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">termbase_path</span> <span class="n">TERMBASE_PATH</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">src_spacy_language_model</span> <span class="n">SRC_SPACY_LANGUAGE_MODEL</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">tgt_spacy_language_model</span> <span class="n">TGT_SPACY_LANGUAGE_MODEL</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">term_corpus_ratio</span> <span class="n">TERM_CORPUS_RATIO</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">term_example_ratio</span> <span class="n">TERM_EXAMPLE_RATIO</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">src_term_stoken</span> <span class="n">SRC_TERM_STOKEN</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">tgt_term_stoken</span> <span class="n">TGT_TERM_STOKEN</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">tgt_term_etoken</span> <span class="n">TGT_TERM_ETOKEN</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">term_source_delimiter</span> <span class="n">TERM_SOURCE_DELIMITER</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">doc_length</span> <span class="n">DOC_LENGTH</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">max_context</span> <span class="n">MAX_CONTEXT</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">reversible_tokenization</span> <span class="p">{</span><span class="n">joiner</span><span class="p">,</span><span class="n">spacer</span><span class="p">}]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">src_seq_length</span> <span class="n">SRC_SEQ_LENGTH</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">tgt_seq_length</span> <span class="n">TGT_SEQ_LENGTH</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">src_prefix</span> <span class="n">SRC_PREFIX</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">tgt_prefix</span> <span class="n">TGT_PREFIX</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">src_suffix</span> <span class="n">SRC_SUFFIX</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">tgt_suffix</span> <span class="n">TGT_SUFFIX</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">tm_path</span> <span class="n">TM_PATH</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">fuzzy_corpus_ratio</span> <span class="n">FUZZY_CORPUS_RATIO</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">fuzzy_threshold</span> <span class="n">FUZZY_THRESHOLD</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">tm_delimiter</span> <span class="n">TM_DELIMITER</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">fuzzy_token</span> <span class="n">FUZZY_TOKEN</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">fuzzymatch_min_length</span> <span class="n">FUZZYMATCH_MIN_LENGTH</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">fuzzymatch_max_length</span> <span class="n">FUZZYMATCH_MAX_LENGTH</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">src_eq_tgt</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">same_char</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">same_word</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">scripts_ok</span> <span class="p">[</span><span class="n">SCRIPTS_OK</span> <span class="o">...</span><span class="p">]]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">scripts_nok</span> <span class="p">[</span><span class="n">SCRIPTS_NOK</span> <span class="o">...</span><span class="p">]]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">src_tgt_ratio</span> <span class="n">SRC_TGT_RATIO</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">avg_tok_min</span> <span class="n">AVG_TOK_MIN</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">avg_tok_max</span> <span class="n">AVG_TOK_MAX</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">langid</span> <span class="p">[</span><span class="n">LANGID</span> <span class="o">...</span><span class="p">]]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">switchout_temperature</span> <span class="n">SWITCHOUT_TEMPERATURE</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">tokendrop_temperature</span> <span class="n">TOKENDROP_TEMPERATURE</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">tokenmask_temperature</span> <span class="n">TOKENMASK_TEMPERATURE</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">src_subword_model</span> <span class="n">SRC_SUBWORD_MODEL</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">tgt_subword_model</span> <span class="n">TGT_SUBWORD_MODEL</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">src_subword_nbest</span> <span class="n">SRC_SUBWORD_NBEST</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">tgt_subword_nbest</span> <span class="n">TGT_SUBWORD_NBEST</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">src_subword_alpha</span> <span class="n">SRC_SUBWORD_ALPHA</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">tgt_subword_alpha</span> <span class="n">TGT_SUBWORD_ALPHA</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">src_subword_vocab</span> <span class="n">SRC_SUBWORD_VOCAB</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">tgt_subword_vocab</span> <span class="n">TGT_SUBWORD_VOCAB</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">src_vocab_threshold</span> <span class="n">SRC_VOCAB_THRESHOLD</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">tgt_vocab_threshold</span> <span class="n">TGT_VOCAB_THRESHOLD</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">src_subword_type</span> <span class="p">{</span><span class="n">none</span><span class="p">,</span><span class="n">sentencepiece</span><span class="p">,</span><span class="n">bpe</span><span class="p">}]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">tgt_subword_type</span> <span class="p">{</span><span class="n">none</span><span class="p">,</span><span class="n">sentencepiece</span><span class="p">,</span><span class="n">bpe</span><span class="p">}]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">src_onmttok_kwargs</span> <span class="n">SRC_ONMTTOK_KWARGS</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">-</span><span class="n">tgt_onmttok_kwargs</span> <span class="n">TGT_ONMTTOK_KWARGS</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">gpt2_pretok</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">src_lang</span> <span class="n">SRC_LANG</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">tgt_lang</span> <span class="n">TGT_LANG</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">penn</span> <span class="n">PENN</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">norm_quote_commas</span> <span class="n">NORM_QUOTE_COMMAS</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">norm_numbers</span> <span class="n">NORM_NUMBERS</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">pre_replace_unicode_punct</span> <span class="n">PRE_REPLACE_UNICODE_PUNCT</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">post_remove_control_chars</span> <span class="n">POST_REMOVE_CONTROL_CHARS</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">seed</span> <span class="n">SEED</span><span class="p">]</span>
</pre></div>
</div>
<section id="Configuration">
<h2>Configuration<a class="headerlink" href="#Configuration" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>-config, --config</kbd></dt>
<dd><p>Path of the main YAML config file.</p>
</dd>
<dt><kbd>-save_config, --save_config</kbd></dt>
<dd><p>Path where to save the config.</p>
</dd>
</dl>
</section>
<section id="Data">
<h2>Data<a class="headerlink" href="#Data" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>-data, --data</kbd></dt>
<dd><p>List of datasets and their specifications. See examples/<a href="#id1"><span class="problematic" id="id2">*</span></a>.yaml for further details.</p>
</dd>
<dt><kbd>-skip_empty_level, --skip_empty_level</kbd></dt>
<dd><p>Possible choices: silent, warning, error</p>
<p>Security level when encounter empty examples.silent: silently ignore/skip empty example;warning: warning when ignore/skip empty example;error: raise error &amp; stop execution when encouter empty.</p>
<p>Default: “warning”</p>
</dd>
<dt><kbd>-transforms, --transforms</kbd></dt>
<dd><p>Possible choices: insert_mask_before_placeholder, uppercase, inlinetags, bart, terminology, docify, inferfeats, filtertoolong, prefix, suffix, fuzzymatch, clean, switchout, tokendrop, tokenmask, sentencepiece, bpe, onmt_tokenize, normalize</p>
<p>Default transform pipeline to apply to data. Can be specified in each corpus of data to override.</p>
<p>Default: []</p>
</dd>
<dt><kbd>-save_data, --save_data</kbd></dt>
<dd><p>Output base path for objects that will be saved (vocab, transforms, embeddings, …).</p>
</dd>
<dt><kbd>-overwrite, --overwrite</kbd></dt>
<dd><p>Overwrite existing objects if any.</p>
<p>Default: False</p>
</dd>
<dt><kbd>-n_sample, --n_sample</kbd></dt>
<dd><p>Build vocab using this number of transformed samples/corpus. Can be [-1, 0, N&gt;0]. Set to -1 to go full corpus, 0 to skip.</p>
<p>Default: 5000</p>
</dd>
<dt><kbd>-dump_samples, --dump_samples</kbd></dt>
<dd><p>Dump samples when building vocab. Warning: this may slow down the process.</p>
<p>Default: False</p>
</dd>
<dt><kbd>-num_threads, --num_threads</kbd></dt>
<dd><p>Number of parallel threads to build the vocab.</p>
<p>Default: 1</p>
</dd>
<dt><kbd>-learn_subwords, --learn_subwords</kbd></dt>
<dd><p>Learn subwords prior to building vocab</p>
<p>Default: False</p>
</dd>
<dt><kbd>-learn_subwords_size, --learn_subwords_size</kbd></dt>
<dd><p>Learn subwords operations</p>
<p>Default: 32000</p>
</dd>
<dt><kbd>-vocab_sample_queue_size, --vocab_sample_queue_size</kbd></dt>
<dd><p>Size of queues used in the build_vocab dump path.</p>
<p>Default: 20</p>
</dd>
</dl>
</section>
<section id="Vocab">
<h2>Vocab<a class="headerlink" href="#Vocab" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>-src_vocab, --src_vocab</kbd></dt>
<dd><p>Path to save src (or shared) vocabulary file. Format: one &lt;word&gt; or &lt;word&gt;      &lt;count&gt; per line.</p>
</dd>
<dt><kbd>-tgt_vocab, --tgt_vocab</kbd></dt>
<dd><p>Path to save tgt vocabulary file. Format: one &lt;word&gt; or &lt;word&gt;  &lt;count&gt; per line.</p>
</dd>
<dt><kbd>-share_vocab, --share_vocab</kbd></dt>
<dd><p>Share source and target vocabulary.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--decoder_start_token, -decoder_start_token</kbd></dt>
<dd><p>Default decoder start token for most ONMT models it is &lt;s&gt; = BOS it happens that for some Fairseq model it requires &lt;/s&gt;</p>
<p>Default: “&lt;s&gt;”</p>
</dd>
<dt><kbd>--default_specials, -default_specials</kbd></dt>
<dd><p>default specials used for Vocab initialization UNK, PAD, BOS, EOS will take IDs 0, 1, 2, 3  typically &lt;unk&gt; &lt;blank&gt; &lt;s&gt; &lt;/s&gt;</p>
<p>Default: [‘&lt;unk&gt;’, ‘&lt;blank&gt;’, ‘&lt;s&gt;’, ‘&lt;/s&gt;’]</p>
</dd>
</dl>
</section>
<section id="Features">
<h2>Features<a class="headerlink" href="#Features" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>-n_src_feats, --n_src_feats</kbd></dt>
<dd><p>Number of source feats.</p>
<p>Default: 0</p>
</dd>
<dt><kbd>-src_feats_defaults, --src_feats_defaults</kbd></dt>
<dd><p>Default features to apply in source in case there are not annotated</p>
</dd>
</dl>
</section>
<section id="Transform/InsertMaskBeforePlaceholdersTransform">
<h2>Transform/InsertMaskBeforePlaceholdersTransform<a class="headerlink" href="#Transform/InsertMaskBeforePlaceholdersTransform" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>--response_patterns, -response_patterns</kbd></dt>
<dd><p>Response patten to locate the end of the prompt</p>
<p>Default: [‘Response : ｟newline｠’]</p>
</dd>
</dl>
</section>
<section id="Transform/Uppercase">
<h2>Transform/Uppercase<a class="headerlink" href="#Transform/Uppercase" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>--upper_corpus_ratio, -upper_corpus_ratio</kbd></dt>
<dd><p>Corpus ratio to apply uppercasing.</p>
<p>Default: 0.01</p>
</dd>
</dl>
</section>
<section id="Transform/InlineTags">
<h2>Transform/InlineTags<a class="headerlink" href="#Transform/InlineTags" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>--tags_dictionary_path, -tags_dictionary_path</kbd></dt>
<dd><p>Path to a flat term dictionary.</p>
</dd>
<dt><kbd>--tags_corpus_ratio, -tags_corpus_ratio</kbd></dt>
<dd><p>Ratio of corpus to augment with tags.</p>
<p>Default: 0.1</p>
</dd>
<dt><kbd>--max_tags, -max_tags</kbd></dt>
<dd><p>Maximum number of tags that can be added to a single sentence.</p>
<p>Default: 12</p>
</dd>
<dt><kbd>--paired_stag, -paired_stag</kbd></dt>
<dd><p>The format of an opening paired inline tag. Must include the character #.</p>
<p>Default: “｟ph_#_beg｠”</p>
</dd>
<dt><kbd>--paired_etag, -paired_etag</kbd></dt>
<dd><p>The format of a closing paired inline tag. Must include the character #.</p>
<p>Default: “｟ph_#_end｠”</p>
</dd>
<dt><kbd>--isolated_tag, -isolated_tag</kbd></dt>
<dd><p>The format of an isolated inline tag. Must include the character #.</p>
<p>Default: “｟ph_#_std｠”</p>
</dd>
<dt><kbd>--src_delimiter, -src_delimiter</kbd></dt>
<dd><p>Any special token used for augmented src sentences. The default is the fuzzy token used in the FuzzyMatch transform.</p>
<p>Default: “｟fuzzy｠”</p>
</dd>
</dl>
</section>
<section id="Transform/BART">
<h2>Transform/BART<a class="headerlink" href="#Transform/BART" title="Permalink to this heading">¶</a></h2>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>This transform will not take effect when building vocabulary.</p>
</div>
<dl class="option-list">
<dt><kbd>--permute_sent_ratio, -permute_sent_ratio</kbd></dt>
<dd><p>Permute this proportion of sentences (boundaries defined by [‘.’, ‘?’, ‘!’]) in all inputs.</p>
<p>Default: 0.0</p>
</dd>
<dt><kbd>--rotate_ratio, -rotate_ratio</kbd></dt>
<dd><p>Rotate this proportion of inputs.</p>
<p>Default: 0.0</p>
</dd>
<dt><kbd>--insert_ratio, -insert_ratio</kbd></dt>
<dd><p>Insert this percentage of additional random tokens.</p>
<p>Default: 0.0</p>
</dd>
<dt><kbd>--random_ratio, -random_ratio</kbd></dt>
<dd><p>Instead of using &lt;mask&gt;, use random token this often.</p>
<p>Default: 0.0</p>
</dd>
<dt><kbd>--mask_ratio, -mask_ratio</kbd></dt>
<dd><p>Fraction of words/subwords that will be masked.</p>
<p>Default: 0.0</p>
</dd>
<dt><kbd>--mask_length, -mask_length</kbd></dt>
<dd><p>Possible choices: subword, word, span-poisson</p>
<p>Length of masking window to apply.</p>
<p>Default: “subword”</p>
</dd>
<dt><kbd>--poisson_lambda, -poisson_lambda</kbd></dt>
<dd><p>Lambda for Poisson distribution to sample span length if <cite>-mask_length</cite> set to span-poisson.</p>
<p>Default: 3.0</p>
</dd>
<dt><kbd>--replace_length, -replace_length</kbd></dt>
<dd><p>Possible choices: -1, 0, 1</p>
<p>When masking N tokens, replace with 0, 1, or N tokens. (use -1 for N)</p>
<p>Default: -1</p>
</dd>
</dl>
</section>
<section id="Transform/Terminology">
<h2>Transform/Terminology<a class="headerlink" href="#Transform/Terminology" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>--termbase_path, -termbase_path</kbd></dt>
<dd><p>Path to a dictionary file with terms.</p>
</dd>
<dt><kbd>--src_spacy_language_model, -src_spacy_language_model</kbd></dt>
<dd><p>Name of the spacy language model for the source corpus.</p>
</dd>
<dt><kbd>--tgt_spacy_language_model, -tgt_spacy_language_model</kbd></dt>
<dd><p>Name of the spacy language model for the target corpus.</p>
</dd>
<dt><kbd>--term_corpus_ratio, -term_corpus_ratio</kbd></dt>
<dd><p>Ratio of corpus to augment with terms.</p>
<p>Default: 0.3</p>
</dd>
<dt><kbd>--term_example_ratio, -term_example_ratio</kbd></dt>
<dd><p>Max terms allowed in an example.</p>
<p>Default: 0.2</p>
</dd>
<dt><kbd>--src_term_stoken, -src_term_stoken</kbd></dt>
<dd><p>The source term start token.</p>
<p>Default: “｟src_term_start｠”</p>
</dd>
<dt><kbd>--tgt_term_stoken, -tgt_term_stoken</kbd></dt>
<dd><p>The target term start token.</p>
<p>Default: “｟tgt_term_start｠”</p>
</dd>
<dt><kbd>--tgt_term_etoken, -tgt_term_etoken</kbd></dt>
<dd><p>The target term end token.</p>
<p>Default: “｟tgt_term_end｠”</p>
</dd>
<dt><kbd>--term_source_delimiter, -term_source_delimiter</kbd></dt>
<dd><p>Any special token used for augmented source sentences. The default is the fuzzy token used in the FuzzyMatch transform.</p>
<p>Default: “｟fuzzy｠”</p>
</dd>
</dl>
</section>
<section id="Transform/Docify">
<h2>Transform/Docify<a class="headerlink" href="#Transform/Docify" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>--doc_length, -doc_length</kbd></dt>
<dd><p>Number of tokens per doc.</p>
<p>Default: 200</p>
</dd>
<dt><kbd>--max_context, -max_context</kbd></dt>
<dd><p>Max context segments.</p>
<p>Default: 1</p>
</dd>
</dl>
</section>
<section id="Transform/InferFeats">
<h2>Transform/InferFeats<a class="headerlink" href="#Transform/InferFeats" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>--reversible_tokenization, -reversible_tokenization</kbd></dt>
<dd><p>Possible choices: joiner, spacer</p>
<p>Type of reversible tokenization applied on the tokenizer.</p>
<p>Default: “joiner”</p>
</dd>
</dl>
</section>
<section id="Transform/Filter">
<h2>Transform/Filter<a class="headerlink" href="#Transform/Filter" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>--src_seq_length, -src_seq_length</kbd></dt>
<dd><p>Maximum source sequence length.</p>
<p>Default: 192</p>
</dd>
<dt><kbd>--tgt_seq_length, -tgt_seq_length</kbd></dt>
<dd><p>Maximum target sequence length.</p>
<p>Default: 192</p>
</dd>
</dl>
</section>
<section id="Transform/Prefix">
<h2>Transform/Prefix<a class="headerlink" href="#Transform/Prefix" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>--src_prefix, -src_prefix</kbd></dt>
<dd><p>String to prepend to all source example.</p>
<p>Default: “”</p>
</dd>
<dt><kbd>--tgt_prefix, -tgt_prefix</kbd></dt>
<dd><p>String to prepend to all target example.</p>
<p>Default: “”</p>
</dd>
</dl>
</section>
<section id="Transform/Suffix">
<h2>Transform/Suffix<a class="headerlink" href="#Transform/Suffix" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>--src_suffix, -src_suffix</kbd></dt>
<dd><p>String to append to all source example.</p>
<p>Default: “”</p>
</dd>
<dt><kbd>--tgt_suffix, -tgt_suffix</kbd></dt>
<dd><p>String to append to all target example.</p>
<p>Default: “”</p>
</dd>
</dl>
</section>
<section id="Transform/FuzzyMatching">
<h2>Transform/FuzzyMatching<a class="headerlink" href="#Transform/FuzzyMatching" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>--tm_path, -tm_path</kbd></dt>
<dd><p>Path to a flat text TM.</p>
</dd>
<dt><kbd>--fuzzy_corpus_ratio, -fuzzy_corpus_ratio</kbd></dt>
<dd><p>Ratio of corpus to augment with fuzzy matches.</p>
<p>Default: 0.1</p>
</dd>
<dt><kbd>--fuzzy_threshold, -fuzzy_threshold</kbd></dt>
<dd><p>The fuzzy matching threshold.</p>
<p>Default: 70</p>
</dd>
<dt><kbd>--tm_delimiter, -tm_delimiter</kbd></dt>
<dd><p>The delimiter used in the flat text TM.</p>
<p>Default: “      “</p>
</dd>
<dt><kbd>--fuzzy_token, -fuzzy_token</kbd></dt>
<dd><p>The fuzzy token to be added with the matches.</p>
<p>Default: “｟fuzzy｠”</p>
</dd>
<dt><kbd>--fuzzymatch_min_length, -fuzzymatch_min_length</kbd></dt>
<dd><p>Min length for TM entries and examples to match.</p>
<p>Default: 4</p>
</dd>
<dt><kbd>--fuzzymatch_max_length, -fuzzymatch_max_length</kbd></dt>
<dd><p>Max length for TM entries and examples to match.</p>
<p>Default: 70</p>
</dd>
</dl>
</section>
<section id="Transform/Clean">
<h2>Transform/Clean<a class="headerlink" href="#Transform/Clean" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>--src_eq_tgt, -src_eq_tgt</kbd></dt>
<dd><p>Remove ex src==tgt</p>
<p>Default: False</p>
</dd>
<dt><kbd>--same_char, -same_char</kbd></dt>
<dd><p>Remove ex with same char more than 4 times</p>
<p>Default: False</p>
</dd>
<dt><kbd>--same_word, -same_word</kbd></dt>
<dd><p>Remove ex with same word more than 3 times</p>
<p>Default: False</p>
</dd>
<dt><kbd>--scripts_ok, -scripts_ok</kbd></dt>
<dd><p>list of unicodata scripts accepted</p>
<p>Default: [‘Latin’, ‘Common’]</p>
</dd>
<dt><kbd>--scripts_nok, -scripts_nok</kbd></dt>
<dd><p>list of unicodata scripts not accepted</p>
<p>Default: []</p>
</dd>
<dt><kbd>--src_tgt_ratio, -src_tgt_ratio</kbd></dt>
<dd><p>ratio between src and tgt</p>
<p>Default: 2</p>
</dd>
<dt><kbd>--avg_tok_min, -avg_tok_min</kbd></dt>
<dd><p>average length of tokens min</p>
<p>Default: 3</p>
</dd>
<dt><kbd>--avg_tok_max, -avg_tok_max</kbd></dt>
<dd><p>average length of tokens max</p>
<p>Default: 20</p>
</dd>
<dt><kbd>--langid, -langid</kbd></dt>
<dd><p>list of languages accepted</p>
<p>Default: []</p>
</dd>
</dl>
</section>
<section id="Transform/SwitchOut">
<h2>Transform/SwitchOut<a class="headerlink" href="#Transform/SwitchOut" title="Permalink to this heading">¶</a></h2>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>This transform will not take effect when building vocabulary.</p>
</div>
<dl class="option-list">
<dt><kbd>-switchout_temperature, --switchout_temperature</kbd></dt>
<dd><p>Sampling temperature for SwitchOut. <span class="math notranslate nohighlight">\(\tau^{-1}\)</span> in <span id="id1">[<a class="reference internal" href="../ref.html#id40" title="Xinyi Wang, Hieu Pham, Zihang Dai, and Graham Neubig. Switchout: an efficient data augmentation algorithm for neural machine translation. CoRR, 2018. URL: http://arxiv.org/abs/1808.07512, arXiv:1808.07512.">WPDN18</a>]</span>. Smaller value makes data more diverse.</p>
<p>Default: 1.0</p>
</dd>
</dl>
</section>
<section id="Transform/Token_Drop">
<h2>Transform/Token_Drop<a class="headerlink" href="#Transform/Token_Drop" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>-tokendrop_temperature, --tokendrop_temperature</kbd></dt>
<dd><p>Sampling temperature for token deletion.</p>
<p>Default: 1.0</p>
</dd>
</dl>
</section>
<section id="Transform/Token_Mask">
<h2>Transform/Token_Mask<a class="headerlink" href="#Transform/Token_Mask" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>-tokenmask_temperature, --tokenmask_temperature</kbd></dt>
<dd><p>Sampling temperature for token masking.</p>
<p>Default: 1.0</p>
</dd>
</dl>
</section>
<section id="Transform/Subword/Common">
<h2>Transform/Subword/Common<a class="headerlink" href="#Transform/Subword/Common" title="Permalink to this heading">¶</a></h2>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p>Common options shared by all subword transforms. Including options for indicate subword model path, <a class="reference external" href="https://arxiv.org/abs/1804.10959">Subword Regularization</a>/<a class="reference external" href="https://arxiv.org/abs/1910.13267">BPE-Dropout</a>, and <a class="reference external" href="https://github.com/rsennrich/subword-nmt#best-practice-advice-for-byte-pair-encoding-in-nmt">Vocabulary Restriction</a>.</p>
</div>
<dl class="option-list">
<dt><kbd>-src_subword_model, --src_subword_model</kbd></dt>
<dd><p>Path of subword model for src (or shared).</p>
</dd>
<dt><kbd>-tgt_subword_model, --tgt_subword_model</kbd></dt>
<dd><p>Path of subword model for tgt.</p>
</dd>
<dt><kbd>-src_subword_nbest, --src_subword_nbest</kbd></dt>
<dd><p>Number of candidates in subword regularization. Valid for unigram sampling, invalid for BPE-dropout. (source side)</p>
<p>Default: 1</p>
</dd>
<dt><kbd>-tgt_subword_nbest, --tgt_subword_nbest</kbd></dt>
<dd><p>Number of candidates in subword regularization. Valid for unigram sampling, invalid for BPE-dropout. (target side)</p>
<p>Default: 1</p>
</dd>
<dt><kbd>-src_subword_alpha, --src_subword_alpha</kbd></dt>
<dd><p>Smoothing parameter for sentencepiece unigram sampling, and dropout probability for BPE-dropout. (source side)</p>
<p>Default: 0</p>
</dd>
<dt><kbd>-tgt_subword_alpha, --tgt_subword_alpha</kbd></dt>
<dd><p>Smoothing parameter for sentencepiece unigram sampling, and dropout probability for BPE-dropout. (target side)</p>
<p>Default: 0</p>
</dd>
<dt><kbd>-src_subword_vocab, --src_subword_vocab</kbd></dt>
<dd><p>Path to the vocabulary file for src subword. Format: &lt;word&gt;     &lt;count&gt; per line.</p>
<p>Default: “”</p>
</dd>
<dt><kbd>-tgt_subword_vocab, --tgt_subword_vocab</kbd></dt>
<dd><p>Path to the vocabulary file for tgt subword. Format: &lt;word&gt;     &lt;count&gt; per line.</p>
<p>Default: “”</p>
</dd>
<dt><kbd>-src_vocab_threshold, --src_vocab_threshold</kbd></dt>
<dd><p>Only produce src subword in src_subword_vocab with  frequency &gt;= src_vocab_threshold.</p>
<p>Default: 0</p>
</dd>
<dt><kbd>-tgt_vocab_threshold, --tgt_vocab_threshold</kbd></dt>
<dd><p>Only produce tgt subword in tgt_subword_vocab with  frequency &gt;= tgt_vocab_threshold.</p>
<p>Default: 0</p>
</dd>
</dl>
</section>
<section id="Transform/Subword/ONMTTOK">
<h2>Transform/Subword/ONMTTOK<a class="headerlink" href="#Transform/Subword/ONMTTOK" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>-src_subword_type, --src_subword_type</kbd></dt>
<dd><p>Possible choices: none, sentencepiece, bpe</p>
<p>Type of subword model for src (or shared) in pyonmttok.</p>
<p>Default: “none”</p>
</dd>
<dt><kbd>-tgt_subword_type, --tgt_subword_type</kbd></dt>
<dd><p>Possible choices: none, sentencepiece, bpe</p>
<p>Type of subword model for tgt in  pyonmttok.</p>
<p>Default: “none”</p>
</dd>
<dt><kbd>-src_onmttok_kwargs, --src_onmttok_kwargs</kbd></dt>
<dd><p>Other pyonmttok options for src in dict string, except subword related options listed earlier.</p>
<p>Default: “{‘mode’: ‘none’}”</p>
</dd>
<dt><kbd>-tgt_onmttok_kwargs, --tgt_onmttok_kwargs</kbd></dt>
<dd><p>Other pyonmttok options for tgt in dict string, except subword related options listed earlier.</p>
<p>Default: “{‘mode’: ‘none’}”</p>
</dd>
<dt><kbd>--gpt2_pretok, -gpt2_pretok</kbd></dt>
<dd><p>Preprocess sentence with byte-level mapping</p>
<p>Default: False</p>
</dd>
</dl>
</section>
<section id="Transform/Normalize">
<h2>Transform/Normalize<a class="headerlink" href="#Transform/Normalize" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>--src_lang, -src_lang</kbd></dt>
<dd><p>Source language code</p>
<p>Default: “”</p>
</dd>
<dt><kbd>--tgt_lang, -tgt_lang</kbd></dt>
<dd><p>Target language code</p>
<p>Default: “”</p>
</dd>
<dt><kbd>--penn, -penn</kbd></dt>
<dd><p>Penn substitution</p>
<p>Default: True</p>
</dd>
<dt><kbd>--norm_quote_commas, -norm_quote_commas</kbd></dt>
<dd><p>Normalize quotations and commas</p>
<p>Default: True</p>
</dd>
<dt><kbd>--norm_numbers, -norm_numbers</kbd></dt>
<dd><p>Normalize numbers</p>
<p>Default: True</p>
</dd>
<dt><kbd>--pre_replace_unicode_punct, -pre_replace_unicode_punct</kbd></dt>
<dd><p>Replace unicode punct</p>
<p>Default: False</p>
</dd>
<dt><kbd>--post_remove_control_chars, -post_remove_control_chars</kbd></dt>
<dd><p>Remove control chars</p>
<p>Default: False</p>
</dd>
</dl>
</section>
<section id="Reproducibility">
<h2>Reproducibility<a class="headerlink" href="#Reproducibility" title="Permalink to this heading">¶</a></h2>
<dl class="option-list">
<dt><kbd>--seed, -seed</kbd></dt>
<dd><p>Set random seed used for better reproducibility between experiments.</p>
<p>Default: -1</p>
</dd>
</dl>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="train.html" class="btn btn-neutral float-right" title="Train" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../examples/replicate_vicuna/ReplicateVicuna.html" class="btn btn-neutral float-left" title="Supervised Finetuning of llama 7B to replicate Vicuna" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017-2023, OpenNMT

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>